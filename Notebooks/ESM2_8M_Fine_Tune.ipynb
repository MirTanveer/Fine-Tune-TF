{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {
    "id": "mD9hZLGBqxYL"
   },
   "source": [
    "# Full Model Fine-Tuning\n",
    "\n",
    "This notebook enables you to fine-tune pretrained language models (PLMs) on your own datasets.\n",
    "\n",
    "To improve efficiency and performance, we employed Parameter-Efficient Fine-Tuning (PEFT) using LoRA (Low-Rank Adaptation of Large Language Models) as described in the other colab file.\n",
    "\n",
    "\n",
    "Note: In this example, we use the relatively small ESM2 8M model to achieve faster training on a single T4 GPU in Google Colab. Larger models or longer sequence lengths will require more GPU memory and significantly longer training times."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {
    "id": "I2fbGeCJHd8e"
   },
   "source": [
    "# Install Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KveEQppzyVkn",
    "outputId": "39e624ad-3fa2-470a-864a-6aaa6dd0c560"
   },
   "outputs": [],
   "source": [
    "# !pip install datasets\n",
    "# !pip install evaluate\n",
    "# !pip install SentencePiece\n",
    "# !pip install transformers[torch]\n",
    "# !pip install peft\n",
    "# !pip install Biopython\n",
    "# !pip install mpi4py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "k9Kqh7TPE6h9",
    "outputId": "14c2b296-c00f-4e8d-a119-e8d56c967c98"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import transformers\n",
    "import datasets as datasets\n",
    "\n",
    "print(\"Torch version: \",torch.__version__)\n",
    "print(\"Cuda version: \",torch.version.cuda)\n",
    "print(\"Numpy version: \",np.__version__)\n",
    "print(\"Pandas version: \",pd.__version__)\n",
    "print(\"Transformers version: \",transformers.__version__)\n",
    "print(\"Datasets version: \",datasets.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {
    "id": "29fa5723-bf2e-4ee9-94c2-128785bbec2b"
   },
   "outputs": [],
   "source": [
    "import torch, numpy as np, random\n",
    "\n",
    "seed = 21\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5",
   "metadata": {
    "id": "SVWo748KrXzI"
   },
   "source": [
    "# Load training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_Goze-3S1Zer",
    "outputId": "7d49197b-b048-4b1a-c0af-6a0427ac2f9f"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from Bio import SeqIO\n",
    "import requests\n",
    "from io import StringIO\n",
    "\n",
    "# GitHub raw link\n",
    "url = 'https://raw.githubusercontent.com/MirTanveer/Fine-Tune-TF/main/Data/First_layer_training.txt'\n",
    "\n",
    "# Fetch the data from GitHub\n",
    "response = requests.get(url)\n",
    "response.raise_for_status()  # ensure the download worked\n",
    "\n",
    "# Parse the FASTA data from the text\n",
    "sequences = []\n",
    "for record in SeqIO.parse(StringIO(response.text), \"fasta\"):\n",
    "    # Example header format: >seq1%someinfo%LABEL=1\n",
    "    description_parts = record.description.split(\"%\")\n",
    "    label = int(description_parts[-1].split(\"LABEL=\")[1])  # Extract numeric label\n",
    "    sequences.append([record.name, str(record.seq), label])\n",
    "\n",
    "# Create a DataFrame\n",
    "df = pd.DataFrame(sequences, columns=[\"name\", \"sequence\", \"label\"])\n",
    "\n",
    "# Display\n",
    "print(df.head())\n",
    "print(\"\\nTotal sequences:\", len(df))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {
    "id": "7df4460e-e7bd-474d-a892-6e03a370439b"
   },
   "outputs": [],
   "source": [
    "from datasets import Dataset\n",
    "# Convert label column to int (already done)\n",
    "df['label'] = df['label'].astype(int)\n",
    "\n",
    "# Optional: Map label to class names if needed\n",
    "label2id = {label: i for i, label in enumerate(sorted(df['label'].unique()))}\n",
    "id2label = {i: label for label, i in label2id.items()}\n",
    "\n",
    "# Convert dataframe to HuggingFace dataset\n",
    "dataset = Dataset.from_pandas(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 156
    },
    "id": "a7abe243-ae76-4154-a1cb-1c1c8b3a3c64",
    "outputId": "b8f9b587-1953-40b9-bc6e-31a42aedf736"
   },
   "outputs": [],
   "source": [
    "type(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9",
   "metadata": {
    "id": "ZaD4qF4vriw9"
   },
   "source": [
    "# Custom Head Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {
    "id": "41d04e12-46c5-44a9-8c1a-79689568e414"
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class CustomHeadClassifier(nn.Module):\n",
    "    def __init__(self, embedding_size, hidden_size, dropout, num_classes):\n",
    "        super(CustomHeadClassifier, self).__init__()\n",
    "        self.fc1 = nn.Linear(embedding_size, hidden_size)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.fc2 = nn.Linear(hidden_size, num_classes)\n",
    "\n",
    "    def forward(self, x, attention_mask=None):\n",
    "        # x shape: (batch_size, seq_len, embedding_size)\n",
    "        if attention_mask is not None:\n",
    "            # masked mean pooling\n",
    "            mask = attention_mask.unsqueeze(-1)  # (batch_size, seq_len, 1)\n",
    "            x = (x * mask).sum(1) / mask.sum(1)\n",
    "        else:\n",
    "            x = x.mean(dim=1)  # mean pooling over sequence\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 336,
     "referenced_widgets": [
      "98af89004bef4ae0a80a6c99b77a6de0",
      "7aa67d7df775455399444d0c9bbfe41d",
      "c74f4b9248f84219a4fac51847deaa63",
      "1d490b980f7d4e0caaec1c3dac4f840d",
      "be7906f529e34ceaacd5e1011607cdb9",
      "8c8dfcd812a04af48b5693cf35aa1fed",
      "7c833437d1694269b1f9008c1a5d6b86",
      "0b7b7bcb30704faca21c07c28af2e6a2",
      "c4240ca0fd9a44e6b043fa5d22ca6051",
      "9b439a5dbcb142c2aaf0bce7b08e1419",
      "ae92a909f86a41aea17fb739b6ede42b",
      "47f45b1f89004655868fbf8780192d64",
      "48aae506d2414482be7777beecde1afa",
      "c343bcf2ba584e248692477049a53db2",
      "b80b60739d5e4170bf8d8fcd17dba766",
      "cfd24e62e38346eebdb4ab7b9f09b3ed",
      "0aeba8043953427da6e059c676aa530f",
      "a233d57ea7d4425ebd9660cda7d1249c",
      "abcf4ae89ac1404c8fb6456b1633f898",
      "026e5ae3a1c74c40aaeb1fdf6d337867",
      "c5efb8595bd64df8867e25bcaa796766",
      "bfbc1345aecf4683bea89ed18f5ca452",
      "c8f4f1de59e64bdba48d72f0d1dae6db",
      "f1a82f5180084233a2eee88a79ff3976",
      "786990fcb5b941e1af651dc6b83e5359",
      "ff6585c56f874eab8e304835d5a6786f",
      "2938df2408f646ab911ad1b8f67d33f9",
      "cc64e26146ff43188fe39baf1c9d635a",
      "002d97c462634f9eb38b83374a16df84",
      "bc27d66b463747348a0859424b4be2a1",
      "49f10a3801a44d6cbe7208c88ffa0844",
      "f9b59001d3b04c65b7c4f34374e337d1",
      "7c9fb9abd2df428d9afe42de00db4c14",
      "fd251301f23e48c19f8eda4950aa62a6",
      "a419994a006149dbba0a42944a664eeb",
      "cbd8004ee59d41c593a3e06ccc9342e3",
      "2479baf61c8c4d6c88d328817a9a2fe3",
      "2ecb106e25594f559057a68194bbdfac",
      "459ffdb7c84a4d069f778d168b141fa0",
      "25364307e3d24cfda378ace6db8442d7",
      "c05731617e1544af9b723c9006bd7dfe",
      "2c8fd2b6a0b14b3f8b047da543f9db65",
      "f562c89e5e7142fd8b9b54f7351838f9",
      "e35ea927feb14803816be0a2be850b11",
      "380dc4dde8f2422f99129f101e865b4f",
      "ae5028e8f50e40d4950d07b967f5db4f",
      "ecec3721a3a94f5682276b219ae1a69b",
      "08edb98b2e074c19ba1fbca2bb1546a1",
      "4de6a21549e14bb788a6fbaa9fbdafcf",
      "7cd43b5a1b16419abc5510b3e97fc593",
      "eccadec585ab44c7ad4d523b1b82cbbe",
      "b18ea744e41e4c31a8cf6c3007e26c46",
      "8a232be4d03a481d843ca7cc0ecf08f9",
      "ff9375563c884209adf3f5e8cdb9ad7e",
      "58cc738a403f45a6ae1617d13d70c239"
     ]
    },
    "id": "22405ee7-c2ab-487a-a074-2eb24b6a8117",
    "outputId": "cfce5ed2-ea94-41ea-daeb-bbbd4788f3f0"
   },
   "outputs": [],
   "source": [
    "#Load tokenzier and model\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "\n",
    "model_name = \"facebook/esm2_t6_8M_UR50D\"  # or other ESM-2 variant\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    model_name,\n",
    "    num_labels=2,\n",
    "    problem_type=\"single_label_classification\"\n",
    ")\n",
    "\n",
    "embedding_size = model.config.hidden_size\n",
    "model.classifier = CustomHeadClassifier(embedding_size, hidden_size=128, dropout=0.3, num_classes=2)\n",
    "model = model.to(\"cuda:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {
    "id": "b4586adb-d725-487d-9deb-f59a102c3259"
   },
   "outputs": [],
   "source": [
    "# Freeze classification head\n",
    "# for param in model.classifier.parameters():\n",
    "#     param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {
    "id": "bbfbbc7a-9a12-4f1f-9cd2-6633411b8bf5"
   },
   "outputs": [],
   "source": [
    "# for name, param in model.named_parameters():\n",
    "#     if param.requires_grad:\n",
    "#         print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4e93c95d-784a-4696-9f75-6a89eab5bc2b",
    "outputId": "a866cc6e-5e0a-4ef1-db37-a2ddafa3ecf2"
   },
   "outputs": [],
   "source": [
    "# Count trainable parameters\n",
    "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "all_params = sum(p.numel() for p in model.parameters())\n",
    "\n",
    "print(f\"Trainable parameters: {trainable_params:,}\")\n",
    "print(f\"Total parameters: {all_params:,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 49,
     "referenced_widgets": [
      "20097a075cee41e9b4b254b654eb096b",
      "495b02dd1eb345f98f8e3cef2082e4be",
      "004570fd61ff432a91fb604ac79cd618",
      "11f2ba4dfdfd4c2d9e18bb233560b637",
      "16daf316682e42789183ffe825d34df3",
      "8fe0639e8d1744288b7662e83990cf32",
      "4315c3b43ceb4ad493fd05928e28a7bb",
      "4576289cedcb44b08e974b8d80ef4f62",
      "93a1c67751dc47c78739948cd4f14482",
      "248854af33fa40acb14baca084f10ecc",
      "12b9b3365cf14326ab896700c8941976"
     ]
    },
    "id": "3fc5ba34-5f51-4250-9e35-1c1e4732246e",
    "outputId": "706b8bed-3703-4ca3-e395-0ee0d31e8191"
   },
   "outputs": [],
   "source": [
    "def tokenize_function(example):\n",
    "    return tokenizer(example[\"sequence\"], truncation=True, padding=\"max_length\", max_length=1024)\n",
    "\n",
    "tokenized_dataset = dataset.map(tokenize_function, batched=True)\n",
    "tokenized_dataset = tokenized_dataset.train_test_split(test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {
    "id": "k06NsRPL3LIJ"
   },
   "outputs": [],
   "source": [
    "# ds_config = {\n",
    "#   \"train_batch_size\": \"auto\",\n",
    "#   \"gradient_accumulation_steps\": \"auto\",\n",
    "#   \"fp16\": {\n",
    "#     \"enabled\": True\n",
    "#   },\n",
    "#   \"zero_optimization\": {\n",
    "#     \"stage\": 2,\n",
    "#     \"offload_optimizer\": {\n",
    "#       \"device\": \"cpu\",\n",
    "#       \"pin_memory\": True\n",
    "#     },\n",
    "#     \"overlap_comm\": True\n",
    "#   },\n",
    "#   \"gradient_clipping\": 1.0\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2a709b74-70ac-4c25-b0a6-06272e9475c3",
    "outputId": "1cf5fd0a-8402-466e-fd9b-622ba60a2f13"
   },
   "outputs": [],
   "source": [
    "trainable = [name for name, param in model.named_parameters() if param.requires_grad]\n",
    "frozen = [name for name, param in model.named_parameters() if not param.requires_grad]\n",
    "\n",
    "print(f\"Trainable layers: {len(trainable)}\")\n",
    "print(trainable[:5])  # print a few\n",
    "\n",
    "print(\"\\n\")\n",
    "\n",
    "print(f\"Frozen layers: {len(frozen)}\")\n",
    "print(frozen[:5])  # print a few\n",
    "\n",
    "\n",
    "\n",
    "from transformers import TrainingArguments\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./ESM2-8M-with-Finetune\",\n",
    "    logging_dir=\"./logs\",\n",
    "    learning_rate=1e-5,\n",
    "    per_device_train_batch_size=1,\n",
    "    per_device_eval_batch_size=1,\n",
    "    gradient_accumulation_steps=8, #Effective gradient_accumulation is 8\n",
    "    num_train_epochs=10,\n",
    "    eval_steps=500,\n",
    "    logging_steps=100,\n",
    "    logging_strategy=\"epoch\",\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    warmup_ratio=0.05,\n",
    "    max_grad_norm=1.0,\n",
    "    fp16=True,\n",
    "    #deepspeed= ds_config,\n",
    "    report_to=\"none\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {
    "id": "3b81e0b9-0e34-4c75-9596-7716f6352e39"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = logits.argmax(axis=-1)\n",
    "    acc = accuracy_score(labels, predictions)\n",
    "    return {\"accuracy\": acc}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {
    "id": "c958d2e3-35c5-4c9d-ac2b-e7358febd644"
   },
   "outputs": [],
   "source": [
    "from transformers import Trainer\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_dataset[\"train\"],\n",
    "    eval_dataset=tokenized_dataset[\"test\"],\n",
    "    processing_class=tokenizer,\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 461
    },
    "id": "ad10c06f-b819-4188-9dd6-9f3a13667f46",
    "outputId": "f1898b84-5a67-43d9-ab15-f3f7326c34c2"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 307
    },
    "id": "88011f9f-0d38-41c5-bddf-f018ad6f76fe",
    "outputId": "3a8227cc-a045-48dc-9a4a-aeb999b8d6ad"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "train_loss, eval_loss, eval_accuracy, epochs = [], [], [], []\n",
    "\n",
    "for entry in trainer.state.log_history:\n",
    "    if \"loss\" in entry and \"epoch\" in entry:\n",
    "        train_loss.append(entry[\"loss\"])\n",
    "    if \"eval_loss\" in entry:\n",
    "        eval_loss.append(entry[\"eval_loss\"])\n",
    "    if \"eval_accuracy\" in entry:\n",
    "        eval_accuracy.append(entry[\"eval_accuracy\"])\n",
    "    if \"epoch\" in entry:\n",
    "        epochs.append(entry[\"epoch\"])\n",
    "\n",
    "# Make sure x-axis aligns\n",
    "x = list(range(1, len(train_loss)+1))\n",
    "\n",
    "fig, ax1 = plt.subplots(figsize=(5, 3))\n",
    "\n",
    "# Plot loss curves on the left y-axis\n",
    "ax1.set_xlabel('Epochs')\n",
    "ax1.set_ylabel('Loss')\n",
    "ax1.plot(x, train_loss,   marker='o')\n",
    "ax1.plot(x, eval_loss,   marker='s')\n",
    "ax1.set_xticks(x)\n",
    "ax1.tick_params(axis='y')\n",
    "\n",
    "# Instantiate a second axes sharing the same x-axis for accuracy\n",
    "ax2 = ax1.twinx()\n",
    "ax2.set_ylabel('Accuracy')\n",
    "ax2.plot(x, eval_accuracy, color='green', marker='^')\n",
    "ax2.tick_params(axis='y')\n",
    "\n",
    "# Combine legends\n",
    "lines_1, labels_1 = ax1.get_legend_handles_labels()\n",
    "lines_2, labels_2 = ax2.get_legend_handles_labels()\n",
    "#ax1.legend(lines_1 + lines_2, labels_1 + labels_2, loc='upper center')\n",
    "#ax2.set_ylim(0.8, 0.95)\n",
    "plt.title('Fine tuning ESM2 8M', fontsize=11)\n",
    "#plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {
    "id": "65812331-c82a-44b6-9efd-34d515e92611"
   },
   "outputs": [],
   "source": [
    "# Directory to save\n",
    "# Save model, tokenzier, and Custom Head Classifier separately\n",
    "# The standard save_pretrained method from Transformers won’t automatically save the custom head class code.\n",
    "# We need to save both the model weights and the custom head properly.\n",
    "\n",
    "save_dir = \"Saved_Models/fine_tuned_ESM2_8M_model_with_a_custom_head\"\n",
    "\n",
    "# Save Hugging Face model weights (excluding custom head)\n",
    "model.save_pretrained(save_dir)\n",
    "tokenizer.save_pretrained(save_dir)\n",
    "\n",
    "# Save custom head weights separately\n",
    "torch.save(model.classifier.state_dict(), f\"{save_dir}/custom_head.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23",
   "metadata": {
    "id": "35236b80-d9e8-4590-a0e2-16fa1d2e4a0c"
   },
   "source": [
    "## Load the saved model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {
    "id": "587ac3bc-b708-41ae-b2eb-3b3a702e7412"
   },
   "outputs": [],
   "source": [
    "#Load the Saved Model\n",
    "\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class CustomHeadClassifier(nn.Module):\n",
    "    def __init__(self, embedding_size, hidden_size, dropout, num_classes):\n",
    "        super(CustomHeadClassifier, self).__init__()\n",
    "        self.fc1 = nn.Linear(embedding_size, hidden_size)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.fc2 = nn.Linear(hidden_size, num_classes)\n",
    "\n",
    "    def forward(self, x, attention_mask=None):\n",
    "        if attention_mask is not None:\n",
    "            mask = attention_mask.unsqueeze(-1)\n",
    "            x = (x * mask).sum(1) / mask.sum(1)\n",
    "        else:\n",
    "            x = x.mean(dim=1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a8cdc82e-444c-48c3-bb21-e413a94688a4",
    "outputId": "743643e3-9653-46ce-ce01-0fbccc1b00d4"
   },
   "outputs": [],
   "source": [
    "save_dir = \"Saved_Models/fine_tuned_ESM2_8M_model_with_a_custom_head\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(save_dir)\n",
    "model_load = AutoModelForSequenceClassification.from_pretrained(save_dir, num_labels=2)\n",
    "embedding_size = model_load.config.hidden_size\n",
    "model_load.classifier = CustomHeadClassifier(embedding_size, hidden_size=128, dropout=0.3, num_classes=2)\n",
    "\n",
    "# Load the trained weights\n",
    "model_load.classifier.load_state_dict(torch.load(f\"{save_dir}/custom_head.pt\"))\n",
    "\n",
    "# Move to GPU if needed\n",
    "model_load = model_load.to(\"cuda:0\")\n",
    "model_load.eval()  # set to evaluation mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "65ad991b-c416-4a9f-a8ee-d848c9699a06",
    "outputId": "aeefc780-cd22-4e12-a929-61c7f00e930c"
   },
   "outputs": [],
   "source": [
    "# Check if CUDA is available\n",
    "import torch\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27",
   "metadata": {
    "id": "OpTR1oBFp2Zr"
   },
   "source": [
    "# Load independent dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b0cfec9b-837c-437c-8a5b-7b70572737fb",
    "outputId": "f87bc916-0b39-4b15-a6d4-1b092e792d34"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from Bio import SeqIO\n",
    "import requests\n",
    "from io import StringIO\n",
    "\n",
    "# GitHub raw link\n",
    "url = 'https://raw.githubusercontent.com/MirTanveer/Fine-Tune-TF/main/Data/First_Layer_Independent.txt'\n",
    "\n",
    "# Fetch the data from GitHub\n",
    "response = requests.get(url)\n",
    "response.raise_for_status()  # ensure the download worked\n",
    "\n",
    "# Parse the FASTA data from the text\n",
    "sequences = []\n",
    "for record in SeqIO.parse(StringIO(response.text), \"fasta\"):\n",
    "    # Example header format: >seq1%someinfo%LABEL=1\n",
    "    description_parts = record.description.split(\"%\")\n",
    "    label = int(description_parts[-1].split(\"LABEL=\")[1])  # Extract numeric label\n",
    "    sequences.append([record.name, str(record.seq), label])\n",
    "\n",
    "# Create a DataFrame\n",
    "df_test= pd.DataFrame(sequences, columns=[\"name\", \"sequence\", \"label\"])\n",
    "\n",
    "# Display\n",
    "print(df_test.head())\n",
    "print(\"\\nTotal sequences:\", len(df_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29",
   "metadata": {
    "id": "cdb9a4b3-19f9-42c2-bbb4-477ce3f9744e"
   },
   "outputs": [],
   "source": [
    "from datasets import Dataset\n",
    "\n",
    "df_test[\"label\"] = df_test[\"label\"].astype(int)\n",
    "test_dataset = Dataset.from_pandas(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 49,
     "referenced_widgets": [
      "366df6c0b3884160aa99ef08b0a68f53",
      "9af09273d87f488499abe7f960ae74cd",
      "09183246aa48455281112c46d407b74b",
      "d5e48d5d39f3465dbc9a28ad25015c2d",
      "ff7c787a488443f7b07e4a864257a23b",
      "eb7e06095590437d9c01ab01ed99d50f",
      "d7f8481aa210450eb302207b27cdbdb6",
      "fe9fd29a2d59421e97ee9bc3efeb955e",
      "ce6f3854b270421ba147bb6873265491",
      "7a3b9be44e064096af02a74da3cbf59e",
      "101ba0249b0a48408f6f59a09df6e3ca"
     ]
    },
    "id": "6c35a18d-f647-4fac-8520-a9d32731944d",
    "outputId": "5192863f-6dd2-4204-9f8d-c7fa71e5123a"
   },
   "outputs": [],
   "source": [
    "def tokenize_function(example):\n",
    "    return tokenizer(example[\"sequence\"], padding=\"max_length\", truncation=True, max_length=1024)\n",
    "\n",
    "test_dataset = test_dataset.map(tokenize_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31",
   "metadata": {
    "id": "686d63c9-5f35-4d0d-87a1-cbfc3104d3cf"
   },
   "outputs": [],
   "source": [
    "# Create Trainer again for evaluation\n",
    "# trainer_loaded = Trainer(model=model, tokenizer=tokenizer)\n",
    "# predictions = trainer_loaded.predict(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 89
    },
    "id": "69f169ee-3a5a-4c11-8921-423c19ae06a3",
    "outputId": "95d8c6c7-8c62-413a-d323-279102c9b3b8"
   },
   "outputs": [],
   "source": [
    "from transformers import Trainer\n",
    "\n",
    "trainer = Trainer(model=model_load, tokenizer=tokenizer)\n",
    "\n",
    "predictions = trainer.predict(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33",
   "metadata": {
    "id": "cbdcdcc2-43fe-487b-99a3-137520904f47"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "logits = predictions.predictions\n",
    "labels = predictions.label_ids\n",
    "preds = np.argmax(logits, axis=-1)\n",
    "probs = F.softmax(torch.tensor(logits), dim=-1).numpy()  # shape: [N, num_classes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ac54288f-b99c-438e-b2ab-351b471a390e",
    "outputId": "e46d0301-bb96-4533-dbba-6a13f2f8b0e0"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "acc = accuracy_score(labels, preds)\n",
    "print(f\"Test Accuracy: {acc:.4f}\")\n",
    "\n",
    "# Optional: detailed report\n",
    "print(classification_report(labels, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 564
    },
    "id": "77e74731-f55e-4933-94d0-d7b7a42e49c7",
    "outputId": "706565a2-d63e-4f70-e9ad-b0625959c13f"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import ConfusionMatrixDisplay, confusion_matrix\n",
    "import seaborn as sns\n",
    "cm = confusion_matrix(labels, preds)\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "plt.xlabel(\"Predicted Label\")\n",
    "plt.ylabel(\"True Label\")\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eedec0cb-c36f-4e03-ba1b-af807ee857e2",
    "outputId": "30d76f85-321f-427b-a603-c898eab19a65"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, roc_auc_score, roc_curve\n",
    "auc = roc_auc_score(labels, probs[:, 1])\n",
    "print(f\"AUC Score (Binary): {auc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37",
   "metadata": {
    "id": "7ff5ec95-8657-417f-9271-4464cb83c557"
   },
   "outputs": [],
   "source": [
    "TN, FP, FN, TP = cm.ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38",
   "metadata": {
    "id": "a63aa525-ca6d-40aa-a320-f2d3be245e54"
   },
   "outputs": [],
   "source": [
    "precision = TP / (TP + FP) if (TP + FP) > 0 else 0\n",
    "specificity= TN / (TN + FP) if (TN + FP) > 0 else 0\n",
    "recall = TP / (TP + FN) if (TP + FN) > 0 else 0  # Recall = Sensitivity\n",
    "# Matthews correlation coefficient\n",
    "import numpy as np\n",
    "numerator = (TP * TN) - (FP * FN)\n",
    "denominator = np.sqrt((TP + FP)*(TP + FN)*(TN + FP)*(TN + FN))\n",
    "mcc = numerator / denominator if denominator > 0 else 0\n",
    "F1_score= (2*precision*recall)/(precision+recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "134e1c5e-3c3f-4e68-8255-ebd71c7db040",
    "outputId": "4e02b884-e367-4562-f9b7-a579d3a777a9"
   },
   "outputs": [],
   "source": [
    "print(\"Precision value is: \", precision)\n",
    "print(\"Specificity value is: \", specificity)\n",
    "print(\"Recall value is: \", recall)\n",
    "print(\"Mcc score is: \", mcc)\n",
    "print(\"F1 Score is: \", F1_score)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
