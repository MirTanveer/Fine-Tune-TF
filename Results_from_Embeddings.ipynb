{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c8b4b51b-b034-48c0-9192-6feb116e63c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "# Load dictionary\n",
    "TF_train_dict = torch.load(\"esm2_t6_8M_UR50D_TF_Training_cls.pt\") #load any model embeddings\n",
    "NTF_train_dict = torch.load(\"esm2_t6_8M_UR50D_NTF_training_cls.pt\")\n",
    "\n",
    "# Extract embeddings as a list of tensors and stack\n",
    "TF_train_tensor = torch.stack([v for v in TF_train_dict.values()])\n",
    "NTF_train_tensor = torch.stack([v for v in NTF_train_dict.values()])\n",
    "\n",
    "# Combine positive and negative samples\n",
    "X_train = torch.cat([TF_train_tensor, NTF_train_tensor], dim=0)\n",
    "\n",
    "# Create labels: 1 for TF, 0 for NTF\n",
    "y_train = torch.cat([\n",
    "    torch.ones(TF_train_tensor.size(0), dtype=torch.long),\n",
    "    torch.zeros(NTF_train_tensor.size(0), dtype=torch.long)\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "38976f9c-bec4-4b11-92ef-4a893437a202",
   "metadata": {},
   "outputs": [],
   "source": [
    "TF_ind_dict = torch.load(\"esm2_t6_8M_UR50D_TF_Ind_cls.pt\")\n",
    "NTF_ind_dict = torch.load(\"esm2_t6_8M_UR50D_NTF_Ind_cls.pt\")\n",
    "\n",
    "TF_ind_tensor = torch.stack([v for v in TF_ind_dict.values()])\n",
    "NTF_ind_tensor = torch.stack([v for v in NTF_ind_dict.values()])\n",
    "\n",
    "X_test = torch.cat([TF_ind_tensor, NTF_ind_tensor], dim=0)\n",
    "y_test = torch.cat([\n",
    "    torch.ones(TF_ind_tensor.size(0), dtype=torch.long),\n",
    "    torch.zeros(NTF_ind_tensor.size(0), dtype=torch.long)\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "117d2fb0-1c56-4b86-8129-2821a8e1694e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "320"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d5a4a1ed-b189-48d1-9ed1-5d2493e7b364",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([829, 320]),\n",
       " torch.Size([829]),\n",
       " torch.Size([212, 320]),\n",
       " torch.Size([212]))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, y_train.shape, X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4512c04f-104c-4d1d-8615-4456f132e173",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "X_train, y_train = X_train.to(device), y_train.to(device)\n",
    "X_test, y_test = X_test.to(device), y_test.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "39d6eff3-58a2-4a51-bd25-05a6fc25a5ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Move to CPU and convert to numpy\n",
    "X_train_cpu = X_train.cpu().numpy()\n",
    "y_train_cpu = y_train.cpu().numpy()\n",
    "\n",
    "# Split: 80% train, 20% validation\n",
    "X_train_split_np, X_val_np, y_train_split_np, y_val_np = train_test_split(\n",
    "    X_train_cpu, y_train_cpu, test_size=0.2, random_state=66, stratify=y_train_cpu\n",
    ")\n",
    "\n",
    "# Convert back to torch tensors\n",
    "X_train_split = torch.tensor(X_train_split_np, dtype=torch.float32, device=device)\n",
    "y_train_split = torch.tensor(y_train_split_np, dtype=torch.long, device=device)\n",
    "X_val = torch.tensor(X_val_np, dtype=torch.float32, device=device)\n",
    "y_val = torch.tensor(y_val_np, dtype=torch.long, device=device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d989e1b0-221d-48bd-a306-322983ef1a40",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "train_dataset = torch.utils.data.TensorDataset(X_train_split, y_train_split)\n",
    "val_dataset = torch.utils.data.TensorDataset(X_val, y_val)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=16, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ca464875-a3d0-4b97-8cdc-d8494b15a45f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class EmsPredictor(nn.Module):\n",
    "    def __init__(self, embedding_size, hidden_size, dropout, num_classes):\n",
    "        super(EmsPredictor, self).__init__()\n",
    "        self.fc1 = nn.Linear(embedding_size, hidden_size)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.fc2 = nn.Linear(hidden_size, num_classes)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)  # logits\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "47e19aa5-7525-4663-ae3c-e6936ba97658",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model, loss, optimizer\n",
    "model = EmsPredictor(embedding_size=len(X_train[0]), hidden_size=128, dropout=0.3, num_classes=2).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8b2f306-056f-4d8e-a730-a171598ebf81",
   "metadata": {},
   "source": [
    "## Single seed training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b1f3627b-d6ef-4ada-b2ae-64a9d40f67d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# epochs = 250  # adjust as needed\n",
    "\n",
    "# for epoch in range(epochs):\n",
    "#     # --- Training ---\n",
    "#     model.train()\n",
    "#     total_loss = 0\n",
    "#     correct_train = 0\n",
    "#     total_train = 0\n",
    "    \n",
    "#     for batch_X, batch_y in train_loader:\n",
    "#         optimizer.zero_grad()\n",
    "#         outputs = model(batch_X)\n",
    "#         loss = criterion(outputs, batch_y)\n",
    "#         loss.backward()\n",
    "#         optimizer.step()\n",
    "#         total_loss += loss.item()\n",
    "        \n",
    "#         preds = torch.argmax(outputs, dim=1)\n",
    "#         correct_train += (preds == batch_y).sum().item()\n",
    "#         total_train += batch_y.size(0)\n",
    "    \n",
    "#     train_acc = correct_train / total_train\n",
    "#     avg_loss = total_loss / len(train_loader)\n",
    "    \n",
    "#     # --- Validation ---\n",
    "#     model.eval()\n",
    "#     correct_val = 0\n",
    "#     total_val = 0\n",
    "#     with torch.no_grad():\n",
    "#         for val_X, val_y in val_loader:\n",
    "#             outputs = model(val_X)\n",
    "#             preds = torch.argmax(outputs, dim=1)\n",
    "#             correct_val += (preds == val_y).sum().item()\n",
    "#             total_val += val_y.size(0)\n",
    "    \n",
    "#     val_acc = correct_val / total_val\n",
    "    \n",
    "#     print(f\"Epoch {epoch+1}/{epochs}, Loss: {avg_loss:.4f}, Train Acc: {train_acc:.4f}, Val Acc: {val_acc:.4f}\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# import torch\n",
    "# import numpy as np\n",
    "# from sklearn.metrics import confusion_matrix, f1_score, matthews_corrcoef, roc_auc_score\n",
    "\n",
    "# # Predictions and labels on independent set\n",
    "# model.eval()\n",
    "# with torch.no_grad():\n",
    "#     logits = model(X_test)\n",
    "#     probs = torch.softmax(logits, dim=1)\n",
    "#     preds = torch.argmax(probs, dim=1).cpu().numpy()\n",
    "#     prob_pos = probs[:, 1].cpu().numpy()\n",
    "#     labels = y_test.cpu().numpy()\n",
    "\n",
    "# # Bootstrap parameters\n",
    "# n_bootstrap = 1000\n",
    "# rng = np.random.default_rng(seed=42)\n",
    "\n",
    "# # Lists to store metrics\n",
    "# accs, senss, specs, mccs, f1s, aucs = [], [], [], [], [], []\n",
    "\n",
    "# for _ in range(n_bootstrap):\n",
    "#     # Sample with replacement\n",
    "#     idx = rng.integers(0, len(labels), len(labels))\n",
    "#     sample_labels = labels[idx]\n",
    "#     sample_preds = preds[idx]\n",
    "#     sample_probs = prob_pos[idx]\n",
    "\n",
    "#     # Confusion matrix\n",
    "#     tn, fp, fn, tp = confusion_matrix(sample_labels, sample_preds, labels=[0,1]).ravel()\n",
    "\n",
    "#     # Metrics\n",
    "#     acc = np.mean(sample_preds == sample_labels)\n",
    "#     sens = tp / (tp + fn) if (tp + fn) > 0 else 0.0\n",
    "#     spec = tn / (tn + fp) if (tn + fp) > 0 else 0.0\n",
    "#     mcc = matthews_corrcoef(sample_labels, sample_preds)\n",
    "#     f1 = f1_score(sample_labels, sample_preds)\n",
    "#     auc = roc_auc_score(sample_labels, sample_probs) if len(np.unique(sample_labels)) > 1 else np.nan\n",
    "\n",
    "#     # Store\n",
    "#     accs.append(acc)\n",
    "#     senss.append(sens)\n",
    "#     specs.append(spec)\n",
    "#     mccs.append(mcc)\n",
    "#     f1s.append(f1)\n",
    "#     if not np.isnan(auc):\n",
    "#         aucs.append(auc)\n",
    "\n",
    "# # Compute mean ± std\n",
    "# print(f\"Accuracy       : {np.mean(accs):.3f} ± {np.std(accs):.3f}\")\n",
    "# print(f\"Sensitivity    : {np.mean(senss):.3f} ± {np.std(senss):.3f}\")\n",
    "# print(f\"Specificity    : {np.mean(specs):.3f} ± {np.std(specs):.3f}\")\n",
    "# print(f\"MCC            : {np.mean(mccs):.3f} ± {np.std(mccs):.3f}\")\n",
    "# print(f\"F1-score       : {np.mean(f1s):.3f} ± {np.std(f1s):.3f}\")\n",
    "# print(f\"AUC-ROC        : {np.mean(aucs):.3f} ± {np.std(aucs):.3f}\")\n",
    "\n",
    "# # Overall confusion matrix on full independent set\n",
    "# cm = confusion_matrix(labels, preds, labels=[0,1])\n",
    "# print(\"\\nOverall Confusion Matrix:\")\n",
    "# print(cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2b8cd03-27cb-4b24-8b58-19d09227441b",
   "metadata": {},
   "source": [
    "## 3 Different Seeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "248091e3-9758-4c82-a082-7c9c931310a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed 42 | Epoch 1/150, Loss: 0.6814, Train Acc: 0.5928, Val Acc: 0.7590\n",
      "Seed 42 | Epoch 2/150, Loss: 0.6595, Train Acc: 0.7014, Val Acc: 0.7410\n",
      "Seed 42 | Epoch 3/150, Loss: 0.6432, Train Acc: 0.7255, Val Acc: 0.7229\n",
      "Seed 42 | Epoch 4/150, Loss: 0.6251, Train Acc: 0.7315, Val Acc: 0.7530\n",
      "Seed 42 | Epoch 5/150, Loss: 0.6036, Train Acc: 0.7587, Val Acc: 0.7771\n",
      "Seed 42 | Epoch 6/150, Loss: 0.5824, Train Acc: 0.7647, Val Acc: 0.7831\n",
      "Seed 42 | Epoch 7/150, Loss: 0.5600, Train Acc: 0.7738, Val Acc: 0.7651\n",
      "Seed 42 | Epoch 8/150, Loss: 0.5414, Train Acc: 0.7873, Val Acc: 0.7831\n",
      "Seed 42 | Epoch 9/150, Loss: 0.5177, Train Acc: 0.7934, Val Acc: 0.7952\n",
      "Seed 42 | Epoch 10/150, Loss: 0.5078, Train Acc: 0.7919, Val Acc: 0.8072\n",
      "Seed 42 | Epoch 11/150, Loss: 0.4940, Train Acc: 0.7888, Val Acc: 0.7952\n",
      "Seed 42 | Epoch 12/150, Loss: 0.4747, Train Acc: 0.8024, Val Acc: 0.8072\n",
      "Seed 42 | Epoch 13/150, Loss: 0.4642, Train Acc: 0.8190, Val Acc: 0.8133\n",
      "Seed 42 | Epoch 14/150, Loss: 0.4512, Train Acc: 0.8054, Val Acc: 0.8193\n",
      "Seed 42 | Epoch 15/150, Loss: 0.4390, Train Acc: 0.8175, Val Acc: 0.8072\n",
      "Seed 42 | Epoch 16/150, Loss: 0.4308, Train Acc: 0.8069, Val Acc: 0.7892\n",
      "Seed 42 | Epoch 17/150, Loss: 0.4174, Train Acc: 0.8235, Val Acc: 0.8133\n",
      "Seed 42 | Epoch 18/150, Loss: 0.4171, Train Acc: 0.8190, Val Acc: 0.8193\n",
      "Seed 42 | Epoch 19/150, Loss: 0.4124, Train Acc: 0.8265, Val Acc: 0.8253\n",
      "Seed 42 | Epoch 20/150, Loss: 0.4064, Train Acc: 0.8250, Val Acc: 0.8133\n",
      "Seed 42 | Epoch 21/150, Loss: 0.3985, Train Acc: 0.8175, Val Acc: 0.8313\n",
      "Seed 42 | Epoch 22/150, Loss: 0.3893, Train Acc: 0.8341, Val Acc: 0.7831\n",
      "Seed 42 | Epoch 23/150, Loss: 0.3813, Train Acc: 0.8296, Val Acc: 0.7952\n",
      "Seed 42 | Epoch 24/150, Loss: 0.3750, Train Acc: 0.8265, Val Acc: 0.8373\n",
      "Seed 42 | Epoch 25/150, Loss: 0.3786, Train Acc: 0.8386, Val Acc: 0.8313\n",
      "Seed 42 | Epoch 26/150, Loss: 0.3651, Train Acc: 0.8477, Val Acc: 0.8373\n",
      "Seed 42 | Epoch 27/150, Loss: 0.3606, Train Acc: 0.8552, Val Acc: 0.8313\n",
      "Seed 42 | Epoch 28/150, Loss: 0.3536, Train Acc: 0.8462, Val Acc: 0.8313\n",
      "Seed 42 | Epoch 29/150, Loss: 0.3508, Train Acc: 0.8612, Val Acc: 0.8193\n",
      "Seed 42 | Epoch 30/150, Loss: 0.3509, Train Acc: 0.8612, Val Acc: 0.8313\n",
      "Seed 42 | Epoch 31/150, Loss: 0.3389, Train Acc: 0.8582, Val Acc: 0.8554\n",
      "Seed 42 | Epoch 32/150, Loss: 0.3470, Train Acc: 0.8552, Val Acc: 0.8494\n",
      "Seed 42 | Epoch 33/150, Loss: 0.3467, Train Acc: 0.8492, Val Acc: 0.8494\n",
      "Seed 42 | Epoch 34/150, Loss: 0.3430, Train Acc: 0.8627, Val Acc: 0.8253\n",
      "Seed 42 | Epoch 35/150, Loss: 0.3264, Train Acc: 0.8703, Val Acc: 0.8494\n",
      "Seed 42 | Epoch 36/150, Loss: 0.3293, Train Acc: 0.8718, Val Acc: 0.8434\n",
      "Seed 42 | Epoch 37/150, Loss: 0.3281, Train Acc: 0.8703, Val Acc: 0.8373\n",
      "Seed 42 | Epoch 38/150, Loss: 0.3256, Train Acc: 0.8778, Val Acc: 0.8253\n",
      "Seed 42 | Epoch 39/150, Loss: 0.3204, Train Acc: 0.8733, Val Acc: 0.8133\n",
      "Seed 42 | Epoch 40/150, Loss: 0.3174, Train Acc: 0.8869, Val Acc: 0.8072\n",
      "Seed 42 | Epoch 41/150, Loss: 0.3086, Train Acc: 0.8748, Val Acc: 0.8313\n",
      "Seed 42 | Epoch 42/150, Loss: 0.3288, Train Acc: 0.8793, Val Acc: 0.8313\n",
      "Seed 42 | Epoch 43/150, Loss: 0.3089, Train Acc: 0.8899, Val Acc: 0.8313\n",
      "Seed 42 | Epoch 44/150, Loss: 0.3075, Train Acc: 0.8718, Val Acc: 0.8072\n",
      "Seed 42 | Epoch 45/150, Loss: 0.3105, Train Acc: 0.8808, Val Acc: 0.8313\n",
      "Seed 42 | Epoch 46/150, Loss: 0.3115, Train Acc: 0.8748, Val Acc: 0.8133\n",
      "Seed 42 | Epoch 47/150, Loss: 0.3021, Train Acc: 0.8929, Val Acc: 0.8133\n",
      "Seed 42 | Epoch 48/150, Loss: 0.3056, Train Acc: 0.8944, Val Acc: 0.8434\n",
      "Seed 42 | Epoch 49/150, Loss: 0.3025, Train Acc: 0.8884, Val Acc: 0.8133\n",
      "Seed 42 | Epoch 50/150, Loss: 0.2993, Train Acc: 0.8869, Val Acc: 0.8072\n",
      "Seed 42 | Epoch 51/150, Loss: 0.2966, Train Acc: 0.8839, Val Acc: 0.8133\n",
      "Seed 42 | Epoch 52/150, Loss: 0.3005, Train Acc: 0.8899, Val Acc: 0.8012\n",
      "Seed 42 | Epoch 53/150, Loss: 0.2949, Train Acc: 0.8899, Val Acc: 0.8193\n",
      "Seed 42 | Epoch 54/150, Loss: 0.2892, Train Acc: 0.8989, Val Acc: 0.8253\n",
      "Seed 42 | Epoch 55/150, Loss: 0.2932, Train Acc: 0.8899, Val Acc: 0.8133\n",
      "Seed 42 | Epoch 56/150, Loss: 0.2927, Train Acc: 0.8974, Val Acc: 0.8133\n",
      "Seed 42 | Epoch 57/150, Loss: 0.2843, Train Acc: 0.8944, Val Acc: 0.8193\n",
      "Seed 42 | Epoch 58/150, Loss: 0.2944, Train Acc: 0.8989, Val Acc: 0.8133\n",
      "Seed 42 | Epoch 59/150, Loss: 0.2873, Train Acc: 0.8929, Val Acc: 0.8072\n",
      "Seed 42 | Epoch 60/150, Loss: 0.2726, Train Acc: 0.8989, Val Acc: 0.8193\n",
      "Seed 42 | Epoch 61/150, Loss: 0.2822, Train Acc: 0.8914, Val Acc: 0.8193\n",
      "Seed 42 | Epoch 62/150, Loss: 0.2793, Train Acc: 0.8929, Val Acc: 0.8133\n",
      "Seed 42 | Epoch 63/150, Loss: 0.2800, Train Acc: 0.8959, Val Acc: 0.8193\n",
      "Seed 42 | Epoch 64/150, Loss: 0.2879, Train Acc: 0.8929, Val Acc: 0.8373\n",
      "Seed 42 | Epoch 65/150, Loss: 0.2793, Train Acc: 0.8929, Val Acc: 0.8373\n",
      "Seed 42 | Epoch 66/150, Loss: 0.2757, Train Acc: 0.8989, Val Acc: 0.8133\n",
      "Seed 42 | Epoch 67/150, Loss: 0.2719, Train Acc: 0.8989, Val Acc: 0.8193\n",
      "Seed 42 | Epoch 68/150, Loss: 0.2693, Train Acc: 0.9050, Val Acc: 0.8193\n",
      "Seed 42 | Epoch 69/150, Loss: 0.2746, Train Acc: 0.8869, Val Acc: 0.8193\n",
      "Seed 42 | Epoch 70/150, Loss: 0.2721, Train Acc: 0.8974, Val Acc: 0.8253\n",
      "Seed 42 | Epoch 71/150, Loss: 0.2698, Train Acc: 0.9035, Val Acc: 0.8193\n",
      "Seed 42 | Epoch 72/150, Loss: 0.2638, Train Acc: 0.9065, Val Acc: 0.8313\n",
      "Seed 42 | Epoch 73/150, Loss: 0.2675, Train Acc: 0.9005, Val Acc: 0.8313\n",
      "Seed 42 | Epoch 74/150, Loss: 0.2748, Train Acc: 0.8959, Val Acc: 0.8253\n",
      "Seed 42 | Epoch 75/150, Loss: 0.2698, Train Acc: 0.9005, Val Acc: 0.8253\n",
      "Seed 42 | Epoch 76/150, Loss: 0.2703, Train Acc: 0.9020, Val Acc: 0.8253\n",
      "Seed 42 | Epoch 77/150, Loss: 0.2571, Train Acc: 0.9095, Val Acc: 0.8193\n",
      "Seed 42 | Epoch 78/150, Loss: 0.2711, Train Acc: 0.9035, Val Acc: 0.8193\n",
      "Seed 42 | Epoch 79/150, Loss: 0.2610, Train Acc: 0.8989, Val Acc: 0.8313\n",
      "Seed 42 | Epoch 80/150, Loss: 0.2580, Train Acc: 0.9110, Val Acc: 0.8313\n",
      "Seed 42 | Epoch 81/150, Loss: 0.2581, Train Acc: 0.9005, Val Acc: 0.8373\n",
      "Seed 42 | Epoch 82/150, Loss: 0.2478, Train Acc: 0.9155, Val Acc: 0.8313\n",
      "Seed 42 | Epoch 83/150, Loss: 0.2549, Train Acc: 0.8989, Val Acc: 0.8373\n",
      "Seed 42 | Epoch 84/150, Loss: 0.2540, Train Acc: 0.9050, Val Acc: 0.8313\n",
      "Seed 42 | Epoch 85/150, Loss: 0.2715, Train Acc: 0.8974, Val Acc: 0.8313\n",
      "Seed 42 | Epoch 86/150, Loss: 0.2441, Train Acc: 0.9155, Val Acc: 0.8313\n",
      "Seed 42 | Epoch 87/150, Loss: 0.2537, Train Acc: 0.9035, Val Acc: 0.8253\n",
      "Seed 42 | Epoch 88/150, Loss: 0.2483, Train Acc: 0.9140, Val Acc: 0.8313\n",
      "Seed 42 | Epoch 89/150, Loss: 0.2481, Train Acc: 0.9050, Val Acc: 0.8313\n",
      "Seed 42 | Epoch 90/150, Loss: 0.2454, Train Acc: 0.9140, Val Acc: 0.8313\n",
      "Seed 42 | Epoch 91/150, Loss: 0.2470, Train Acc: 0.9080, Val Acc: 0.8313\n",
      "Seed 42 | Epoch 92/150, Loss: 0.2487, Train Acc: 0.9095, Val Acc: 0.8313\n",
      "Seed 42 | Epoch 93/150, Loss: 0.2531, Train Acc: 0.9050, Val Acc: 0.8373\n",
      "Seed 42 | Epoch 94/150, Loss: 0.2457, Train Acc: 0.9080, Val Acc: 0.8313\n",
      "Seed 42 | Epoch 95/150, Loss: 0.2436, Train Acc: 0.9065, Val Acc: 0.8373\n",
      "Seed 42 | Epoch 96/150, Loss: 0.2422, Train Acc: 0.9201, Val Acc: 0.8253\n",
      "Seed 42 | Epoch 97/150, Loss: 0.2420, Train Acc: 0.9080, Val Acc: 0.8614\n",
      "Seed 42 | Epoch 98/150, Loss: 0.2402, Train Acc: 0.9095, Val Acc: 0.8313\n",
      "Seed 42 | Epoch 99/150, Loss: 0.2424, Train Acc: 0.9110, Val Acc: 0.8313\n",
      "Seed 42 | Epoch 100/150, Loss: 0.2406, Train Acc: 0.9095, Val Acc: 0.8313\n",
      "Seed 42 | Epoch 101/150, Loss: 0.2344, Train Acc: 0.9140, Val Acc: 0.8373\n",
      "Seed 42 | Epoch 102/150, Loss: 0.2431, Train Acc: 0.9110, Val Acc: 0.8373\n",
      "Seed 42 | Epoch 103/150, Loss: 0.2380, Train Acc: 0.9140, Val Acc: 0.8434\n",
      "Seed 42 | Epoch 104/150, Loss: 0.2361, Train Acc: 0.9155, Val Acc: 0.8313\n",
      "Seed 42 | Epoch 105/150, Loss: 0.2406, Train Acc: 0.9125, Val Acc: 0.8373\n",
      "Seed 42 | Epoch 106/150, Loss: 0.2315, Train Acc: 0.9155, Val Acc: 0.8434\n",
      "Seed 42 | Epoch 107/150, Loss: 0.2281, Train Acc: 0.9155, Val Acc: 0.8253\n",
      "Seed 42 | Epoch 108/150, Loss: 0.2258, Train Acc: 0.9155, Val Acc: 0.8373\n",
      "Seed 42 | Epoch 109/150, Loss: 0.2373, Train Acc: 0.9155, Val Acc: 0.8373\n",
      "Seed 42 | Epoch 110/150, Loss: 0.2358, Train Acc: 0.9186, Val Acc: 0.8434\n",
      "Seed 42 | Epoch 111/150, Loss: 0.2311, Train Acc: 0.9140, Val Acc: 0.8554\n",
      "Seed 42 | Epoch 112/150, Loss: 0.2346, Train Acc: 0.9140, Val Acc: 0.8313\n",
      "Seed 42 | Epoch 113/150, Loss: 0.2287, Train Acc: 0.9201, Val Acc: 0.8253\n",
      "Seed 42 | Epoch 114/150, Loss: 0.2353, Train Acc: 0.9125, Val Acc: 0.8434\n",
      "Seed 42 | Epoch 115/150, Loss: 0.2281, Train Acc: 0.9125, Val Acc: 0.8434\n",
      "Seed 42 | Epoch 116/150, Loss: 0.2271, Train Acc: 0.9201, Val Acc: 0.8253\n",
      "Seed 42 | Epoch 117/150, Loss: 0.2270, Train Acc: 0.9201, Val Acc: 0.8373\n",
      "Seed 42 | Epoch 118/150, Loss: 0.2306, Train Acc: 0.9155, Val Acc: 0.8434\n",
      "Seed 42 | Epoch 119/150, Loss: 0.2234, Train Acc: 0.9140, Val Acc: 0.8373\n",
      "Seed 42 | Epoch 120/150, Loss: 0.2202, Train Acc: 0.9155, Val Acc: 0.8313\n",
      "Seed 42 | Epoch 121/150, Loss: 0.2218, Train Acc: 0.9231, Val Acc: 0.8434\n",
      "Seed 42 | Epoch 122/150, Loss: 0.2195, Train Acc: 0.9216, Val Acc: 0.8373\n",
      "Seed 42 | Epoch 123/150, Loss: 0.2189, Train Acc: 0.9170, Val Acc: 0.8313\n",
      "Seed 42 | Epoch 124/150, Loss: 0.2159, Train Acc: 0.9186, Val Acc: 0.8373\n",
      "Seed 42 | Epoch 125/150, Loss: 0.2184, Train Acc: 0.9231, Val Acc: 0.8373\n",
      "Seed 42 | Epoch 126/150, Loss: 0.2192, Train Acc: 0.9170, Val Acc: 0.8434\n",
      "Seed 42 | Epoch 127/150, Loss: 0.2240, Train Acc: 0.9095, Val Acc: 0.8373\n",
      "Seed 42 | Epoch 128/150, Loss: 0.2187, Train Acc: 0.9140, Val Acc: 0.8434\n",
      "Seed 42 | Epoch 129/150, Loss: 0.2177, Train Acc: 0.9201, Val Acc: 0.8373\n",
      "Seed 42 | Epoch 130/150, Loss: 0.2138, Train Acc: 0.9170, Val Acc: 0.8373\n",
      "Seed 42 | Epoch 131/150, Loss: 0.2126, Train Acc: 0.9170, Val Acc: 0.8373\n",
      "Seed 42 | Epoch 132/150, Loss: 0.2203, Train Acc: 0.9246, Val Acc: 0.8373\n",
      "Seed 42 | Epoch 133/150, Loss: 0.2192, Train Acc: 0.9125, Val Acc: 0.8373\n",
      "Seed 42 | Epoch 134/150, Loss: 0.2085, Train Acc: 0.9216, Val Acc: 0.8373\n",
      "Seed 42 | Epoch 135/150, Loss: 0.2102, Train Acc: 0.9201, Val Acc: 0.8373\n",
      "Seed 42 | Epoch 136/150, Loss: 0.2129, Train Acc: 0.9276, Val Acc: 0.8373\n",
      "Seed 42 | Epoch 137/150, Loss: 0.2119, Train Acc: 0.9201, Val Acc: 0.8373\n",
      "Seed 42 | Epoch 138/150, Loss: 0.2153, Train Acc: 0.9231, Val Acc: 0.8373\n",
      "Seed 42 | Epoch 139/150, Loss: 0.2052, Train Acc: 0.9186, Val Acc: 0.8373\n",
      "Seed 42 | Epoch 140/150, Loss: 0.2171, Train Acc: 0.9170, Val Acc: 0.8373\n",
      "Seed 42 | Epoch 141/150, Loss: 0.2100, Train Acc: 0.9201, Val Acc: 0.8434\n",
      "Seed 42 | Epoch 142/150, Loss: 0.2160, Train Acc: 0.9186, Val Acc: 0.8373\n",
      "Seed 42 | Epoch 143/150, Loss: 0.2030, Train Acc: 0.9291, Val Acc: 0.8373\n",
      "Seed 42 | Epoch 144/150, Loss: 0.2057, Train Acc: 0.9170, Val Acc: 0.8373\n",
      "Seed 42 | Epoch 145/150, Loss: 0.2025, Train Acc: 0.9155, Val Acc: 0.8373\n",
      "Seed 42 | Epoch 146/150, Loss: 0.2050, Train Acc: 0.9170, Val Acc: 0.8313\n",
      "Seed 42 | Epoch 147/150, Loss: 0.1983, Train Acc: 0.9170, Val Acc: 0.8494\n",
      "Seed 42 | Epoch 148/150, Loss: 0.2066, Train Acc: 0.9276, Val Acc: 0.8373\n",
      "Seed 42 | Epoch 149/150, Loss: 0.2003, Train Acc: 0.9246, Val Acc: 0.8373\n",
      "Seed 42 | Epoch 150/150, Loss: 0.1922, Train Acc: 0.9291, Val Acc: 0.8313\n",
      "\n",
      "Independent Evaluation (Seed 42)\n",
      "Accuracy       : 0.850 ± 0.024\n",
      "Sensitivity    : 0.887 ± 0.032\n",
      "Specificity    : 0.812 ± 0.036\n",
      "MCC            : 0.701 ± 0.048\n",
      "F1-score       : 0.854 ± 0.026\n",
      "AUC-ROC        : 0.944 ± 0.015\n",
      "\n",
      "Overall Confusion Matrix:\n",
      "[[86 20]\n",
      " [12 94]]\n",
      "Seed 33 | Epoch 1/150, Loss: 0.6867, Train Acc: 0.5415, Val Acc: 0.6325\n",
      "Seed 33 | Epoch 2/150, Loss: 0.6634, Train Acc: 0.6471, Val Acc: 0.7410\n",
      "Seed 33 | Epoch 3/150, Loss: 0.6505, Train Acc: 0.6878, Val Acc: 0.7771\n",
      "Seed 33 | Epoch 4/150, Loss: 0.6250, Train Acc: 0.7164, Val Acc: 0.7349\n",
      "Seed 33 | Epoch 5/150, Loss: 0.6126, Train Acc: 0.7451, Val Acc: 0.7831\n",
      "Seed 33 | Epoch 6/150, Loss: 0.5880, Train Acc: 0.7662, Val Acc: 0.7410\n",
      "Seed 33 | Epoch 7/150, Loss: 0.5661, Train Acc: 0.7828, Val Acc: 0.8012\n",
      "Seed 33 | Epoch 8/150, Loss: 0.5412, Train Acc: 0.7949, Val Acc: 0.8012\n",
      "Seed 33 | Epoch 9/150, Loss: 0.5178, Train Acc: 0.7753, Val Acc: 0.7952\n",
      "Seed 33 | Epoch 10/150, Loss: 0.5062, Train Acc: 0.8100, Val Acc: 0.7952\n",
      "Seed 33 | Epoch 11/150, Loss: 0.4883, Train Acc: 0.7858, Val Acc: 0.8072\n",
      "Seed 33 | Epoch 12/150, Loss: 0.4813, Train Acc: 0.8054, Val Acc: 0.7952\n",
      "Seed 33 | Epoch 13/150, Loss: 0.4575, Train Acc: 0.8145, Val Acc: 0.8133\n",
      "Seed 33 | Epoch 14/150, Loss: 0.4433, Train Acc: 0.8100, Val Acc: 0.8133\n",
      "Seed 33 | Epoch 15/150, Loss: 0.4426, Train Acc: 0.8100, Val Acc: 0.8133\n",
      "Seed 33 | Epoch 16/150, Loss: 0.4280, Train Acc: 0.8130, Val Acc: 0.8193\n",
      "Seed 33 | Epoch 17/150, Loss: 0.4184, Train Acc: 0.8235, Val Acc: 0.7952\n",
      "Seed 33 | Epoch 18/150, Loss: 0.4125, Train Acc: 0.8250, Val Acc: 0.8373\n",
      "Seed 33 | Epoch 19/150, Loss: 0.4065, Train Acc: 0.8296, Val Acc: 0.8373\n",
      "Seed 33 | Epoch 20/150, Loss: 0.4014, Train Acc: 0.8296, Val Acc: 0.8313\n",
      "Seed 33 | Epoch 21/150, Loss: 0.3889, Train Acc: 0.8356, Val Acc: 0.8373\n",
      "Seed 33 | Epoch 22/150, Loss: 0.3885, Train Acc: 0.8431, Val Acc: 0.8253\n",
      "Seed 33 | Epoch 23/150, Loss: 0.3828, Train Acc: 0.8446, Val Acc: 0.8072\n",
      "Seed 33 | Epoch 24/150, Loss: 0.3783, Train Acc: 0.8416, Val Acc: 0.8253\n",
      "Seed 33 | Epoch 25/150, Loss: 0.3647, Train Acc: 0.8552, Val Acc: 0.8373\n",
      "Seed 33 | Epoch 26/150, Loss: 0.3668, Train Acc: 0.8401, Val Acc: 0.8253\n",
      "Seed 33 | Epoch 27/150, Loss: 0.3619, Train Acc: 0.8582, Val Acc: 0.8373\n",
      "Seed 33 | Epoch 28/150, Loss: 0.3613, Train Acc: 0.8507, Val Acc: 0.8253\n",
      "Seed 33 | Epoch 29/150, Loss: 0.3570, Train Acc: 0.8582, Val Acc: 0.8373\n",
      "Seed 33 | Epoch 30/150, Loss: 0.3438, Train Acc: 0.8567, Val Acc: 0.8253\n",
      "Seed 33 | Epoch 31/150, Loss: 0.3515, Train Acc: 0.8627, Val Acc: 0.8434\n",
      "Seed 33 | Epoch 32/150, Loss: 0.3362, Train Acc: 0.8673, Val Acc: 0.8434\n",
      "Seed 33 | Epoch 33/150, Loss: 0.3439, Train Acc: 0.8643, Val Acc: 0.8434\n",
      "Seed 33 | Epoch 34/150, Loss: 0.3287, Train Acc: 0.8643, Val Acc: 0.8012\n",
      "Seed 33 | Epoch 35/150, Loss: 0.3322, Train Acc: 0.8748, Val Acc: 0.8494\n",
      "Seed 33 | Epoch 36/150, Loss: 0.3270, Train Acc: 0.8839, Val Acc: 0.8193\n",
      "Seed 33 | Epoch 37/150, Loss: 0.3252, Train Acc: 0.8763, Val Acc: 0.8494\n",
      "Seed 33 | Epoch 38/150, Loss: 0.3277, Train Acc: 0.8733, Val Acc: 0.8494\n",
      "Seed 33 | Epoch 39/150, Loss: 0.3262, Train Acc: 0.8688, Val Acc: 0.8494\n",
      "Seed 33 | Epoch 40/150, Loss: 0.3240, Train Acc: 0.8703, Val Acc: 0.8494\n",
      "Seed 33 | Epoch 41/150, Loss: 0.3193, Train Acc: 0.8718, Val Acc: 0.8434\n",
      "Seed 33 | Epoch 42/150, Loss: 0.3137, Train Acc: 0.8733, Val Acc: 0.8072\n",
      "Seed 33 | Epoch 43/150, Loss: 0.3164, Train Acc: 0.8748, Val Acc: 0.8012\n",
      "Seed 33 | Epoch 44/150, Loss: 0.3101, Train Acc: 0.8793, Val Acc: 0.8434\n",
      "Seed 33 | Epoch 45/150, Loss: 0.3081, Train Acc: 0.8808, Val Acc: 0.8133\n",
      "Seed 33 | Epoch 46/150, Loss: 0.3130, Train Acc: 0.8899, Val Acc: 0.8072\n",
      "Seed 33 | Epoch 47/150, Loss: 0.3064, Train Acc: 0.8808, Val Acc: 0.8313\n",
      "Seed 33 | Epoch 48/150, Loss: 0.3035, Train Acc: 0.8929, Val Acc: 0.8193\n",
      "Seed 33 | Epoch 49/150, Loss: 0.2988, Train Acc: 0.8808, Val Acc: 0.8434\n",
      "Seed 33 | Epoch 50/150, Loss: 0.3034, Train Acc: 0.8854, Val Acc: 0.8133\n",
      "Seed 33 | Epoch 51/150, Loss: 0.2999, Train Acc: 0.8824, Val Acc: 0.8193\n",
      "Seed 33 | Epoch 52/150, Loss: 0.2890, Train Acc: 0.8944, Val Acc: 0.8494\n",
      "Seed 33 | Epoch 53/150, Loss: 0.2900, Train Acc: 0.9020, Val Acc: 0.8253\n",
      "Seed 33 | Epoch 54/150, Loss: 0.2903, Train Acc: 0.8974, Val Acc: 0.8373\n",
      "Seed 33 | Epoch 55/150, Loss: 0.2898, Train Acc: 0.8839, Val Acc: 0.8012\n",
      "Seed 33 | Epoch 56/150, Loss: 0.2912, Train Acc: 0.8824, Val Acc: 0.8133\n",
      "Seed 33 | Epoch 57/150, Loss: 0.2992, Train Acc: 0.8808, Val Acc: 0.8193\n",
      "Seed 33 | Epoch 58/150, Loss: 0.2839, Train Acc: 0.8884, Val Acc: 0.8253\n",
      "Seed 33 | Epoch 59/150, Loss: 0.2917, Train Acc: 0.8884, Val Acc: 0.8193\n",
      "Seed 33 | Epoch 60/150, Loss: 0.2837, Train Acc: 0.8989, Val Acc: 0.8313\n",
      "Seed 33 | Epoch 61/150, Loss: 0.2776, Train Acc: 0.8929, Val Acc: 0.8133\n",
      "Seed 33 | Epoch 62/150, Loss: 0.2791, Train Acc: 0.8959, Val Acc: 0.8313\n",
      "Seed 33 | Epoch 63/150, Loss: 0.2768, Train Acc: 0.9080, Val Acc: 0.8193\n",
      "Seed 33 | Epoch 64/150, Loss: 0.2739, Train Acc: 0.8974, Val Acc: 0.8193\n",
      "Seed 33 | Epoch 65/150, Loss: 0.2832, Train Acc: 0.8944, Val Acc: 0.8133\n",
      "Seed 33 | Epoch 66/150, Loss: 0.2754, Train Acc: 0.8944, Val Acc: 0.8133\n",
      "Seed 33 | Epoch 67/150, Loss: 0.2831, Train Acc: 0.8959, Val Acc: 0.8373\n",
      "Seed 33 | Epoch 68/150, Loss: 0.2763, Train Acc: 0.9035, Val Acc: 0.8313\n",
      "Seed 33 | Epoch 69/150, Loss: 0.2642, Train Acc: 0.9050, Val Acc: 0.8253\n",
      "Seed 33 | Epoch 70/150, Loss: 0.2671, Train Acc: 0.9110, Val Acc: 0.8313\n",
      "Seed 33 | Epoch 71/150, Loss: 0.2743, Train Acc: 0.9035, Val Acc: 0.8253\n",
      "Seed 33 | Epoch 72/150, Loss: 0.2691, Train Acc: 0.8989, Val Acc: 0.8253\n",
      "Seed 33 | Epoch 73/150, Loss: 0.2702, Train Acc: 0.8944, Val Acc: 0.8253\n",
      "Seed 33 | Epoch 74/150, Loss: 0.2768, Train Acc: 0.9005, Val Acc: 0.8193\n",
      "Seed 33 | Epoch 75/150, Loss: 0.2634, Train Acc: 0.9080, Val Acc: 0.8313\n",
      "Seed 33 | Epoch 76/150, Loss: 0.2625, Train Acc: 0.9005, Val Acc: 0.8313\n",
      "Seed 33 | Epoch 77/150, Loss: 0.2679, Train Acc: 0.9080, Val Acc: 0.8253\n",
      "Seed 33 | Epoch 78/150, Loss: 0.2620, Train Acc: 0.9080, Val Acc: 0.8373\n",
      "Seed 33 | Epoch 79/150, Loss: 0.2621, Train Acc: 0.9035, Val Acc: 0.8313\n",
      "Seed 33 | Epoch 80/150, Loss: 0.2651, Train Acc: 0.9050, Val Acc: 0.8373\n",
      "Seed 33 | Epoch 81/150, Loss: 0.2559, Train Acc: 0.9110, Val Acc: 0.8313\n",
      "Seed 33 | Epoch 82/150, Loss: 0.2559, Train Acc: 0.9080, Val Acc: 0.8373\n",
      "Seed 33 | Epoch 83/150, Loss: 0.2606, Train Acc: 0.9050, Val Acc: 0.8373\n",
      "Seed 33 | Epoch 84/150, Loss: 0.2545, Train Acc: 0.9095, Val Acc: 0.8373\n",
      "Seed 33 | Epoch 85/150, Loss: 0.2510, Train Acc: 0.9080, Val Acc: 0.8253\n",
      "Seed 33 | Epoch 86/150, Loss: 0.2605, Train Acc: 0.9065, Val Acc: 0.8253\n",
      "Seed 33 | Epoch 87/150, Loss: 0.2514, Train Acc: 0.9065, Val Acc: 0.8253\n",
      "Seed 33 | Epoch 88/150, Loss: 0.2545, Train Acc: 0.9065, Val Acc: 0.8253\n",
      "Seed 33 | Epoch 89/150, Loss: 0.2585, Train Acc: 0.9065, Val Acc: 0.8434\n",
      "Seed 33 | Epoch 90/150, Loss: 0.2520, Train Acc: 0.9080, Val Acc: 0.8434\n",
      "Seed 33 | Epoch 91/150, Loss: 0.2458, Train Acc: 0.9065, Val Acc: 0.8373\n",
      "Seed 33 | Epoch 92/150, Loss: 0.2463, Train Acc: 0.9095, Val Acc: 0.8193\n",
      "Seed 33 | Epoch 93/150, Loss: 0.2366, Train Acc: 0.9125, Val Acc: 0.8253\n",
      "Seed 33 | Epoch 94/150, Loss: 0.2490, Train Acc: 0.9065, Val Acc: 0.8373\n",
      "Seed 33 | Epoch 95/150, Loss: 0.2440, Train Acc: 0.9140, Val Acc: 0.8313\n",
      "Seed 33 | Epoch 96/150, Loss: 0.2416, Train Acc: 0.9155, Val Acc: 0.8253\n",
      "Seed 33 | Epoch 97/150, Loss: 0.2418, Train Acc: 0.9065, Val Acc: 0.8253\n",
      "Seed 33 | Epoch 98/150, Loss: 0.2417, Train Acc: 0.9080, Val Acc: 0.8253\n",
      "Seed 33 | Epoch 99/150, Loss: 0.2361, Train Acc: 0.9140, Val Acc: 0.8253\n",
      "Seed 33 | Epoch 100/150, Loss: 0.2353, Train Acc: 0.9155, Val Acc: 0.8373\n",
      "Seed 33 | Epoch 101/150, Loss: 0.2359, Train Acc: 0.9110, Val Acc: 0.8434\n",
      "Seed 33 | Epoch 102/150, Loss: 0.2379, Train Acc: 0.9065, Val Acc: 0.8434\n",
      "Seed 33 | Epoch 103/150, Loss: 0.2288, Train Acc: 0.9201, Val Acc: 0.8133\n",
      "Seed 33 | Epoch 104/150, Loss: 0.2407, Train Acc: 0.9140, Val Acc: 0.8373\n",
      "Seed 33 | Epoch 105/150, Loss: 0.2324, Train Acc: 0.9186, Val Acc: 0.8373\n",
      "Seed 33 | Epoch 106/150, Loss: 0.2428, Train Acc: 0.9186, Val Acc: 0.8373\n",
      "Seed 33 | Epoch 107/150, Loss: 0.2300, Train Acc: 0.9170, Val Acc: 0.8373\n",
      "Seed 33 | Epoch 108/150, Loss: 0.2446, Train Acc: 0.9065, Val Acc: 0.8434\n",
      "Seed 33 | Epoch 109/150, Loss: 0.2297, Train Acc: 0.9140, Val Acc: 0.8313\n",
      "Seed 33 | Epoch 110/150, Loss: 0.2274, Train Acc: 0.9276, Val Acc: 0.8253\n",
      "Seed 33 | Epoch 111/150, Loss: 0.2188, Train Acc: 0.9246, Val Acc: 0.8193\n",
      "Seed 33 | Epoch 112/150, Loss: 0.2228, Train Acc: 0.9170, Val Acc: 0.8373\n",
      "Seed 33 | Epoch 113/150, Loss: 0.2256, Train Acc: 0.9155, Val Acc: 0.8373\n",
      "Seed 33 | Epoch 114/150, Loss: 0.2263, Train Acc: 0.9186, Val Acc: 0.8313\n",
      "Seed 33 | Epoch 115/150, Loss: 0.2306, Train Acc: 0.9140, Val Acc: 0.8313\n",
      "Seed 33 | Epoch 116/150, Loss: 0.2186, Train Acc: 0.9201, Val Acc: 0.8313\n",
      "Seed 33 | Epoch 117/150, Loss: 0.2432, Train Acc: 0.9095, Val Acc: 0.8373\n",
      "Seed 33 | Epoch 118/150, Loss: 0.2250, Train Acc: 0.9155, Val Acc: 0.8434\n",
      "Seed 33 | Epoch 119/150, Loss: 0.2242, Train Acc: 0.9170, Val Acc: 0.8373\n",
      "Seed 33 | Epoch 120/150, Loss: 0.2196, Train Acc: 0.9125, Val Acc: 0.8373\n",
      "Seed 33 | Epoch 121/150, Loss: 0.2223, Train Acc: 0.9246, Val Acc: 0.8494\n",
      "Seed 33 | Epoch 122/150, Loss: 0.2115, Train Acc: 0.9155, Val Acc: 0.8373\n",
      "Seed 33 | Epoch 123/150, Loss: 0.2232, Train Acc: 0.9155, Val Acc: 0.8434\n",
      "Seed 33 | Epoch 124/150, Loss: 0.2144, Train Acc: 0.9201, Val Acc: 0.8373\n",
      "Seed 33 | Epoch 125/150, Loss: 0.2200, Train Acc: 0.9216, Val Acc: 0.8373\n",
      "Seed 33 | Epoch 126/150, Loss: 0.2171, Train Acc: 0.9231, Val Acc: 0.8373\n",
      "Seed 33 | Epoch 127/150, Loss: 0.2139, Train Acc: 0.9201, Val Acc: 0.8373\n",
      "Seed 33 | Epoch 128/150, Loss: 0.2173, Train Acc: 0.9155, Val Acc: 0.8373\n",
      "Seed 33 | Epoch 129/150, Loss: 0.2119, Train Acc: 0.9186, Val Acc: 0.8373\n",
      "Seed 33 | Epoch 130/150, Loss: 0.2180, Train Acc: 0.9261, Val Acc: 0.8373\n",
      "Seed 33 | Epoch 131/150, Loss: 0.2195, Train Acc: 0.9246, Val Acc: 0.8434\n",
      "Seed 33 | Epoch 132/150, Loss: 0.2140, Train Acc: 0.9155, Val Acc: 0.8434\n",
      "Seed 33 | Epoch 133/150, Loss: 0.2152, Train Acc: 0.9155, Val Acc: 0.8313\n",
      "Seed 33 | Epoch 134/150, Loss: 0.2115, Train Acc: 0.9231, Val Acc: 0.8494\n",
      "Seed 33 | Epoch 135/150, Loss: 0.2141, Train Acc: 0.9186, Val Acc: 0.8313\n",
      "Seed 33 | Epoch 136/150, Loss: 0.2052, Train Acc: 0.9231, Val Acc: 0.8434\n",
      "Seed 33 | Epoch 137/150, Loss: 0.2106, Train Acc: 0.9231, Val Acc: 0.8373\n",
      "Seed 33 | Epoch 138/150, Loss: 0.2110, Train Acc: 0.9231, Val Acc: 0.8253\n",
      "Seed 33 | Epoch 139/150, Loss: 0.2105, Train Acc: 0.9246, Val Acc: 0.8434\n",
      "Seed 33 | Epoch 140/150, Loss: 0.2121, Train Acc: 0.9125, Val Acc: 0.8434\n",
      "Seed 33 | Epoch 141/150, Loss: 0.2149, Train Acc: 0.9216, Val Acc: 0.8494\n",
      "Seed 33 | Epoch 142/150, Loss: 0.2038, Train Acc: 0.9140, Val Acc: 0.8434\n",
      "Seed 33 | Epoch 143/150, Loss: 0.2068, Train Acc: 0.9291, Val Acc: 0.8373\n",
      "Seed 33 | Epoch 144/150, Loss: 0.2041, Train Acc: 0.9246, Val Acc: 0.8373\n",
      "Seed 33 | Epoch 145/150, Loss: 0.2031, Train Acc: 0.9246, Val Acc: 0.8434\n",
      "Seed 33 | Epoch 146/150, Loss: 0.2111, Train Acc: 0.9231, Val Acc: 0.8434\n",
      "Seed 33 | Epoch 147/150, Loss: 0.2048, Train Acc: 0.9186, Val Acc: 0.8253\n",
      "Seed 33 | Epoch 148/150, Loss: 0.2035, Train Acc: 0.9231, Val Acc: 0.8373\n",
      "Seed 33 | Epoch 149/150, Loss: 0.2010, Train Acc: 0.9231, Val Acc: 0.8494\n",
      "Seed 33 | Epoch 150/150, Loss: 0.1956, Train Acc: 0.9321, Val Acc: 0.8253\n",
      "\n",
      "Independent Evaluation (Seed 33)\n",
      "Accuracy       : 0.854 ± 0.025\n",
      "Sensitivity    : 0.915 ± 0.027\n",
      "Specificity    : 0.793 ± 0.040\n",
      "MCC            : 0.713 ± 0.048\n",
      "F1-score       : 0.862 ± 0.025\n",
      "AUC-ROC        : 0.945 ± 0.015\n",
      "\n",
      "Overall Confusion Matrix:\n",
      "[[84 22]\n",
      " [ 9 97]]\n",
      "Seed 101 | Epoch 1/150, Loss: 0.6837, Train Acc: 0.5656, Val Acc: 0.8133\n",
      "Seed 101 | Epoch 2/150, Loss: 0.6643, Train Acc: 0.6998, Val Acc: 0.8133\n",
      "Seed 101 | Epoch 3/150, Loss: 0.6450, Train Acc: 0.7496, Val Acc: 0.8193\n",
      "Seed 101 | Epoch 4/150, Loss: 0.6233, Train Acc: 0.7722, Val Acc: 0.8133\n",
      "Seed 101 | Epoch 5/150, Loss: 0.6061, Train Acc: 0.7662, Val Acc: 0.8133\n",
      "Seed 101 | Epoch 6/150, Loss: 0.5824, Train Acc: 0.7768, Val Acc: 0.7892\n",
      "Seed 101 | Epoch 7/150, Loss: 0.5667, Train Acc: 0.7662, Val Acc: 0.8072\n",
      "Seed 101 | Epoch 8/150, Loss: 0.5452, Train Acc: 0.7783, Val Acc: 0.8012\n",
      "Seed 101 | Epoch 9/150, Loss: 0.5251, Train Acc: 0.7919, Val Acc: 0.8133\n",
      "Seed 101 | Epoch 10/150, Loss: 0.5062, Train Acc: 0.7964, Val Acc: 0.8072\n",
      "Seed 101 | Epoch 11/150, Loss: 0.4927, Train Acc: 0.8009, Val Acc: 0.8133\n",
      "Seed 101 | Epoch 12/150, Loss: 0.4793, Train Acc: 0.7964, Val Acc: 0.8072\n",
      "Seed 101 | Epoch 13/150, Loss: 0.4680, Train Acc: 0.7949, Val Acc: 0.8133\n",
      "Seed 101 | Epoch 14/150, Loss: 0.4539, Train Acc: 0.8296, Val Acc: 0.8133\n",
      "Seed 101 | Epoch 15/150, Loss: 0.4476, Train Acc: 0.8039, Val Acc: 0.8133\n",
      "Seed 101 | Epoch 16/150, Loss: 0.4307, Train Acc: 0.8145, Val Acc: 0.8193\n",
      "Seed 101 | Epoch 17/150, Loss: 0.4216, Train Acc: 0.8265, Val Acc: 0.8133\n",
      "Seed 101 | Epoch 18/150, Loss: 0.4165, Train Acc: 0.8296, Val Acc: 0.7952\n",
      "Seed 101 | Epoch 19/150, Loss: 0.4073, Train Acc: 0.8386, Val Acc: 0.8253\n",
      "Seed 101 | Epoch 20/150, Loss: 0.4003, Train Acc: 0.8265, Val Acc: 0.8072\n",
      "Seed 101 | Epoch 21/150, Loss: 0.4067, Train Acc: 0.8265, Val Acc: 0.8072\n",
      "Seed 101 | Epoch 22/150, Loss: 0.3885, Train Acc: 0.8341, Val Acc: 0.8253\n",
      "Seed 101 | Epoch 23/150, Loss: 0.3847, Train Acc: 0.8326, Val Acc: 0.8072\n",
      "Seed 101 | Epoch 24/150, Loss: 0.3878, Train Acc: 0.8371, Val Acc: 0.8253\n",
      "Seed 101 | Epoch 25/150, Loss: 0.3744, Train Acc: 0.8371, Val Acc: 0.8253\n",
      "Seed 101 | Epoch 26/150, Loss: 0.3710, Train Acc: 0.8416, Val Acc: 0.8133\n",
      "Seed 101 | Epoch 27/150, Loss: 0.3562, Train Acc: 0.8537, Val Acc: 0.8313\n",
      "Seed 101 | Epoch 28/150, Loss: 0.3710, Train Acc: 0.8507, Val Acc: 0.8313\n",
      "Seed 101 | Epoch 29/150, Loss: 0.3592, Train Acc: 0.8492, Val Acc: 0.8253\n",
      "Seed 101 | Epoch 30/150, Loss: 0.3532, Train Acc: 0.8582, Val Acc: 0.8253\n",
      "Seed 101 | Epoch 31/150, Loss: 0.3494, Train Acc: 0.8627, Val Acc: 0.8373\n",
      "Seed 101 | Epoch 32/150, Loss: 0.3449, Train Acc: 0.8567, Val Acc: 0.8373\n",
      "Seed 101 | Epoch 33/150, Loss: 0.3518, Train Acc: 0.8567, Val Acc: 0.8313\n",
      "Seed 101 | Epoch 34/150, Loss: 0.3433, Train Acc: 0.8537, Val Acc: 0.8434\n",
      "Seed 101 | Epoch 35/150, Loss: 0.3359, Train Acc: 0.8567, Val Acc: 0.8434\n",
      "Seed 101 | Epoch 36/150, Loss: 0.3264, Train Acc: 0.8718, Val Acc: 0.8133\n",
      "Seed 101 | Epoch 37/150, Loss: 0.3252, Train Acc: 0.8658, Val Acc: 0.8253\n",
      "Seed 101 | Epoch 38/150, Loss: 0.3263, Train Acc: 0.8703, Val Acc: 0.8072\n",
      "Seed 101 | Epoch 39/150, Loss: 0.3235, Train Acc: 0.8703, Val Acc: 0.8434\n",
      "Seed 101 | Epoch 40/150, Loss: 0.3231, Train Acc: 0.8778, Val Acc: 0.8253\n",
      "Seed 101 | Epoch 41/150, Loss: 0.3189, Train Acc: 0.8763, Val Acc: 0.8494\n",
      "Seed 101 | Epoch 42/150, Loss: 0.3128, Train Acc: 0.8748, Val Acc: 0.8373\n",
      "Seed 101 | Epoch 43/150, Loss: 0.3155, Train Acc: 0.8793, Val Acc: 0.8494\n",
      "Seed 101 | Epoch 44/150, Loss: 0.3051, Train Acc: 0.8763, Val Acc: 0.8133\n",
      "Seed 101 | Epoch 45/150, Loss: 0.3088, Train Acc: 0.8748, Val Acc: 0.8373\n",
      "Seed 101 | Epoch 46/150, Loss: 0.3055, Train Acc: 0.8854, Val Acc: 0.8434\n",
      "Seed 101 | Epoch 47/150, Loss: 0.3052, Train Acc: 0.8808, Val Acc: 0.8494\n",
      "Seed 101 | Epoch 48/150, Loss: 0.3059, Train Acc: 0.8869, Val Acc: 0.8133\n",
      "Seed 101 | Epoch 49/150, Loss: 0.3022, Train Acc: 0.8929, Val Acc: 0.8072\n",
      "Seed 101 | Epoch 50/150, Loss: 0.3000, Train Acc: 0.8944, Val Acc: 0.8434\n",
      "Seed 101 | Epoch 51/150, Loss: 0.3000, Train Acc: 0.8869, Val Acc: 0.8193\n",
      "Seed 101 | Epoch 52/150, Loss: 0.2962, Train Acc: 0.8899, Val Acc: 0.8012\n",
      "Seed 101 | Epoch 53/150, Loss: 0.2950, Train Acc: 0.8899, Val Acc: 0.8373\n",
      "Seed 101 | Epoch 54/150, Loss: 0.3032, Train Acc: 0.8854, Val Acc: 0.8193\n",
      "Seed 101 | Epoch 55/150, Loss: 0.2789, Train Acc: 0.8974, Val Acc: 0.8072\n",
      "Seed 101 | Epoch 56/150, Loss: 0.2920, Train Acc: 0.9065, Val Acc: 0.8193\n",
      "Seed 101 | Epoch 57/150, Loss: 0.2943, Train Acc: 0.8929, Val Acc: 0.8313\n",
      "Seed 101 | Epoch 58/150, Loss: 0.3028, Train Acc: 0.8808, Val Acc: 0.8193\n",
      "Seed 101 | Epoch 59/150, Loss: 0.2926, Train Acc: 0.8839, Val Acc: 0.8193\n",
      "Seed 101 | Epoch 60/150, Loss: 0.2918, Train Acc: 0.8914, Val Acc: 0.8133\n",
      "Seed 101 | Epoch 61/150, Loss: 0.2906, Train Acc: 0.8763, Val Acc: 0.8373\n",
      "Seed 101 | Epoch 62/150, Loss: 0.2833, Train Acc: 0.8944, Val Acc: 0.8434\n",
      "Seed 101 | Epoch 63/150, Loss: 0.2770, Train Acc: 0.8989, Val Acc: 0.8193\n",
      "Seed 101 | Epoch 64/150, Loss: 0.2815, Train Acc: 0.8944, Val Acc: 0.8253\n",
      "Seed 101 | Epoch 65/150, Loss: 0.2781, Train Acc: 0.8989, Val Acc: 0.8072\n",
      "Seed 101 | Epoch 66/150, Loss: 0.2785, Train Acc: 0.9035, Val Acc: 0.8193\n",
      "Seed 101 | Epoch 67/150, Loss: 0.2745, Train Acc: 0.8974, Val Acc: 0.8253\n",
      "Seed 101 | Epoch 68/150, Loss: 0.2690, Train Acc: 0.9140, Val Acc: 0.8193\n",
      "Seed 101 | Epoch 69/150, Loss: 0.2762, Train Acc: 0.9035, Val Acc: 0.8133\n",
      "Seed 101 | Epoch 70/150, Loss: 0.2691, Train Acc: 0.8989, Val Acc: 0.8434\n",
      "Seed 101 | Epoch 71/150, Loss: 0.2706, Train Acc: 0.9005, Val Acc: 0.8253\n",
      "Seed 101 | Epoch 72/150, Loss: 0.2839, Train Acc: 0.8884, Val Acc: 0.8133\n",
      "Seed 101 | Epoch 73/150, Loss: 0.2658, Train Acc: 0.9005, Val Acc: 0.8133\n",
      "Seed 101 | Epoch 74/150, Loss: 0.2755, Train Acc: 0.8959, Val Acc: 0.8434\n",
      "Seed 101 | Epoch 75/150, Loss: 0.2700, Train Acc: 0.9005, Val Acc: 0.8253\n",
      "Seed 101 | Epoch 76/150, Loss: 0.2692, Train Acc: 0.9035, Val Acc: 0.8313\n",
      "Seed 101 | Epoch 77/150, Loss: 0.2573, Train Acc: 0.9050, Val Acc: 0.8313\n",
      "Seed 101 | Epoch 78/150, Loss: 0.2593, Train Acc: 0.9035, Val Acc: 0.8133\n",
      "Seed 101 | Epoch 79/150, Loss: 0.2617, Train Acc: 0.9140, Val Acc: 0.8313\n",
      "Seed 101 | Epoch 80/150, Loss: 0.2632, Train Acc: 0.9080, Val Acc: 0.8253\n",
      "Seed 101 | Epoch 81/150, Loss: 0.2566, Train Acc: 0.9050, Val Acc: 0.8373\n",
      "Seed 101 | Epoch 82/150, Loss: 0.2574, Train Acc: 0.9110, Val Acc: 0.8373\n",
      "Seed 101 | Epoch 83/150, Loss: 0.2620, Train Acc: 0.9125, Val Acc: 0.8434\n",
      "Seed 101 | Epoch 84/150, Loss: 0.2615, Train Acc: 0.9035, Val Acc: 0.8253\n",
      "Seed 101 | Epoch 85/150, Loss: 0.2519, Train Acc: 0.9125, Val Acc: 0.8373\n",
      "Seed 101 | Epoch 86/150, Loss: 0.2646, Train Acc: 0.9050, Val Acc: 0.8373\n",
      "Seed 101 | Epoch 87/150, Loss: 0.2510, Train Acc: 0.9035, Val Acc: 0.8193\n",
      "Seed 101 | Epoch 88/150, Loss: 0.2435, Train Acc: 0.9110, Val Acc: 0.8313\n",
      "Seed 101 | Epoch 89/150, Loss: 0.2545, Train Acc: 0.9065, Val Acc: 0.8373\n",
      "Seed 101 | Epoch 90/150, Loss: 0.2529, Train Acc: 0.9035, Val Acc: 0.8313\n",
      "Seed 101 | Epoch 91/150, Loss: 0.2423, Train Acc: 0.9095, Val Acc: 0.8313\n",
      "Seed 101 | Epoch 92/150, Loss: 0.2548, Train Acc: 0.9020, Val Acc: 0.8434\n",
      "Seed 101 | Epoch 93/150, Loss: 0.2434, Train Acc: 0.9110, Val Acc: 0.8313\n",
      "Seed 101 | Epoch 94/150, Loss: 0.2392, Train Acc: 0.9216, Val Acc: 0.8313\n",
      "Seed 101 | Epoch 95/150, Loss: 0.2431, Train Acc: 0.9065, Val Acc: 0.8494\n",
      "Seed 101 | Epoch 96/150, Loss: 0.2445, Train Acc: 0.9155, Val Acc: 0.8434\n",
      "Seed 101 | Epoch 97/150, Loss: 0.2451, Train Acc: 0.9216, Val Acc: 0.8133\n",
      "Seed 101 | Epoch 98/150, Loss: 0.2499, Train Acc: 0.9080, Val Acc: 0.8373\n",
      "Seed 101 | Epoch 99/150, Loss: 0.2434, Train Acc: 0.9125, Val Acc: 0.8494\n",
      "Seed 101 | Epoch 100/150, Loss: 0.2499, Train Acc: 0.9080, Val Acc: 0.8193\n",
      "Seed 101 | Epoch 101/150, Loss: 0.2448, Train Acc: 0.9095, Val Acc: 0.8193\n",
      "Seed 101 | Epoch 102/150, Loss: 0.2424, Train Acc: 0.9125, Val Acc: 0.8494\n",
      "Seed 101 | Epoch 103/150, Loss: 0.2368, Train Acc: 0.9125, Val Acc: 0.8072\n",
      "Seed 101 | Epoch 104/150, Loss: 0.2339, Train Acc: 0.9201, Val Acc: 0.8434\n",
      "Seed 101 | Epoch 105/150, Loss: 0.2306, Train Acc: 0.9216, Val Acc: 0.8373\n",
      "Seed 101 | Epoch 106/150, Loss: 0.2492, Train Acc: 0.9125, Val Acc: 0.8373\n",
      "Seed 101 | Epoch 107/150, Loss: 0.2244, Train Acc: 0.9170, Val Acc: 0.8072\n",
      "Seed 101 | Epoch 108/150, Loss: 0.2394, Train Acc: 0.9095, Val Acc: 0.8373\n",
      "Seed 101 | Epoch 109/150, Loss: 0.2371, Train Acc: 0.9140, Val Acc: 0.8373\n",
      "Seed 101 | Epoch 110/150, Loss: 0.2412, Train Acc: 0.9050, Val Acc: 0.8434\n",
      "Seed 101 | Epoch 111/150, Loss: 0.2389, Train Acc: 0.9065, Val Acc: 0.8133\n",
      "Seed 101 | Epoch 112/150, Loss: 0.2331, Train Acc: 0.9170, Val Acc: 0.8133\n",
      "Seed 101 | Epoch 113/150, Loss: 0.2266, Train Acc: 0.9155, Val Acc: 0.8494\n",
      "Seed 101 | Epoch 114/150, Loss: 0.2263, Train Acc: 0.9216, Val Acc: 0.8373\n",
      "Seed 101 | Epoch 115/150, Loss: 0.2244, Train Acc: 0.9201, Val Acc: 0.8373\n",
      "Seed 101 | Epoch 116/150, Loss: 0.2253, Train Acc: 0.9216, Val Acc: 0.8373\n",
      "Seed 101 | Epoch 117/150, Loss: 0.2211, Train Acc: 0.9170, Val Acc: 0.8373\n",
      "Seed 101 | Epoch 118/150, Loss: 0.2241, Train Acc: 0.9216, Val Acc: 0.8434\n",
      "Seed 101 | Epoch 119/150, Loss: 0.2260, Train Acc: 0.9186, Val Acc: 0.8373\n",
      "Seed 101 | Epoch 120/150, Loss: 0.2221, Train Acc: 0.9170, Val Acc: 0.8193\n",
      "Seed 101 | Epoch 121/150, Loss: 0.2239, Train Acc: 0.9231, Val Acc: 0.8133\n",
      "Seed 101 | Epoch 122/150, Loss: 0.2287, Train Acc: 0.9140, Val Acc: 0.8373\n",
      "Seed 101 | Epoch 123/150, Loss: 0.2155, Train Acc: 0.9065, Val Acc: 0.8313\n",
      "Seed 101 | Epoch 124/150, Loss: 0.2216, Train Acc: 0.9186, Val Acc: 0.8434\n",
      "Seed 101 | Epoch 125/150, Loss: 0.2156, Train Acc: 0.9261, Val Acc: 0.8434\n",
      "Seed 101 | Epoch 126/150, Loss: 0.2210, Train Acc: 0.9276, Val Acc: 0.8253\n",
      "Seed 101 | Epoch 127/150, Loss: 0.2320, Train Acc: 0.9186, Val Acc: 0.8253\n",
      "Seed 101 | Epoch 128/150, Loss: 0.2153, Train Acc: 0.9216, Val Acc: 0.8373\n",
      "Seed 101 | Epoch 129/150, Loss: 0.2070, Train Acc: 0.9306, Val Acc: 0.8434\n",
      "Seed 101 | Epoch 130/150, Loss: 0.2191, Train Acc: 0.9140, Val Acc: 0.8434\n",
      "Seed 101 | Epoch 131/150, Loss: 0.2097, Train Acc: 0.9216, Val Acc: 0.8434\n",
      "Seed 101 | Epoch 132/150, Loss: 0.2154, Train Acc: 0.9155, Val Acc: 0.8434\n",
      "Seed 101 | Epoch 133/150, Loss: 0.2151, Train Acc: 0.9216, Val Acc: 0.8373\n",
      "Seed 101 | Epoch 134/150, Loss: 0.2141, Train Acc: 0.9155, Val Acc: 0.8434\n",
      "Seed 101 | Epoch 135/150, Loss: 0.2172, Train Acc: 0.9216, Val Acc: 0.8373\n",
      "Seed 101 | Epoch 136/150, Loss: 0.2148, Train Acc: 0.9291, Val Acc: 0.8434\n",
      "Seed 101 | Epoch 137/150, Loss: 0.2102, Train Acc: 0.9306, Val Acc: 0.8434\n",
      "Seed 101 | Epoch 138/150, Loss: 0.2100, Train Acc: 0.9246, Val Acc: 0.8434\n",
      "Seed 101 | Epoch 139/150, Loss: 0.2025, Train Acc: 0.9276, Val Acc: 0.8434\n",
      "Seed 101 | Epoch 140/150, Loss: 0.2170, Train Acc: 0.9186, Val Acc: 0.8494\n",
      "Seed 101 | Epoch 141/150, Loss: 0.2093, Train Acc: 0.9276, Val Acc: 0.8434\n",
      "Seed 101 | Epoch 142/150, Loss: 0.2072, Train Acc: 0.9216, Val Acc: 0.8434\n",
      "Seed 101 | Epoch 143/150, Loss: 0.2108, Train Acc: 0.9246, Val Acc: 0.8434\n",
      "Seed 101 | Epoch 144/150, Loss: 0.2095, Train Acc: 0.9231, Val Acc: 0.8373\n",
      "Seed 101 | Epoch 145/150, Loss: 0.2029, Train Acc: 0.9186, Val Acc: 0.8373\n",
      "Seed 101 | Epoch 146/150, Loss: 0.2049, Train Acc: 0.9216, Val Acc: 0.8373\n",
      "Seed 101 | Epoch 147/150, Loss: 0.2014, Train Acc: 0.9261, Val Acc: 0.8434\n",
      "Seed 101 | Epoch 148/150, Loss: 0.2143, Train Acc: 0.9110, Val Acc: 0.8494\n",
      "Seed 101 | Epoch 149/150, Loss: 0.2050, Train Acc: 0.9231, Val Acc: 0.8494\n",
      "Seed 101 | Epoch 150/150, Loss: 0.2071, Train Acc: 0.9276, Val Acc: 0.8434\n",
      "\n",
      "Independent Evaluation (Seed 101)\n",
      "Accuracy       : 0.867 ± 0.023\n",
      "Sensitivity    : 0.878 ± 0.032\n",
      "Specificity    : 0.857 ± 0.034\n",
      "MCC            : 0.735 ± 0.047\n",
      "F1-score       : 0.868 ± 0.025\n",
      "AUC-ROC        : 0.944 ± 0.015\n",
      "\n",
      "Overall Confusion Matrix:\n",
      "[[91 15]\n",
      " [13 93]]\n",
      "\n",
      "=== Final Average over 3 seeds ===\n",
      "ACC         : 0.857 ± 0.008\n",
      "SENS        : 0.893 ± 0.016\n",
      "SPEC        : 0.821 ± 0.027\n",
      "MCC         : 0.716 ± 0.014\n",
      "F1          : 0.861 ± 0.006\n",
      "AUC         : 0.944 ± 0.001\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix, f1_score, matthews_corrcoef, roc_auc_score\n",
    "\n",
    "# Function to train, validate, and test with bootstrap for a given seed\n",
    "def run_pipeline(seed):\n",
    "    torch.manual_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "\n",
    "    # --- Training loop ---\n",
    "    epochs = 150\n",
    "    for epoch in range(epochs):\n",
    "        # --- Training ---\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "        correct_train = 0\n",
    "        total_train = 0\n",
    "        \n",
    "        for batch_X, batch_y in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(batch_X)\n",
    "            loss = criterion(outputs, batch_y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "            \n",
    "            preds = torch.argmax(outputs, dim=1)\n",
    "            correct_train += (preds == batch_y).sum().item()\n",
    "            total_train += batch_y.size(0)\n",
    "        \n",
    "        train_acc = correct_train / total_train\n",
    "        avg_loss = total_loss / len(train_loader)\n",
    "        \n",
    "        # --- Validation ---\n",
    "        model.eval()\n",
    "        correct_val = 0\n",
    "        total_val = 0\n",
    "        with torch.no_grad():\n",
    "            for val_X, val_y in val_loader:\n",
    "                outputs = model(val_X)\n",
    "                preds = torch.argmax(outputs, dim=1)\n",
    "                correct_val += (preds == val_y).sum().item()\n",
    "                total_val += val_y.size(0)\n",
    "        \n",
    "        val_acc = correct_val / total_val\n",
    "        \n",
    "        print(f\"Seed {seed} | Epoch {epoch+1}/{epochs}, Loss: {avg_loss:.4f}, Train Acc: {train_acc:.4f}, Val Acc: {val_acc:.4f}\")\n",
    "\n",
    "    # --- Independent set evaluation ---\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        logits = model(X_test)\n",
    "        probs = torch.softmax(logits, dim=1)\n",
    "        preds = torch.argmax(probs, dim=1).cpu().numpy()\n",
    "        prob_pos = probs[:, 1].cpu().numpy()\n",
    "        labels = y_test.cpu().numpy()\n",
    "\n",
    "    # Bootstrap parameters\n",
    "    n_bootstrap = 1000\n",
    "    rng = np.random.default_rng(seed=seed)\n",
    "\n",
    "    # Lists to store metrics\n",
    "    accs, senss, specs, mccs, f1s, aucs = [], [], [], [], [], []\n",
    "\n",
    "    for _ in range(n_bootstrap):\n",
    "        # Sample with replacement\n",
    "        idx = rng.integers(0, len(labels), len(labels))\n",
    "        sample_labels = labels[idx]\n",
    "        sample_preds = preds[idx]\n",
    "        sample_probs = prob_pos[idx]\n",
    "\n",
    "        # Confusion matrix\n",
    "        tn, fp, fn, tp = confusion_matrix(sample_labels, sample_preds, labels=[0,1]).ravel()\n",
    "\n",
    "        # Metrics\n",
    "        acc = np.mean(sample_preds == sample_labels)\n",
    "        sens = tp / (tp + fn) if (tp + fn) > 0 else 0.0\n",
    "        spec = tn / (tn + fp) if (tn + fp) > 0 else 0.0\n",
    "        mcc = matthews_corrcoef(sample_labels, sample_preds)\n",
    "        f1 = f1_score(sample_labels, sample_preds)\n",
    "        auc = roc_auc_score(sample_labels, sample_probs) if len(np.unique(sample_labels)) > 1 else np.nan\n",
    "\n",
    "        accs.append(acc)\n",
    "        senss.append(sens)\n",
    "        specs.append(spec)\n",
    "        mccs.append(mcc)\n",
    "        f1s.append(f1)\n",
    "        if not np.isnan(auc):\n",
    "            aucs.append(auc)\n",
    "\n",
    "    # Print independent results for this seed\n",
    "    print(f\"\\nIndependent Evaluation (Seed {seed})\")\n",
    "    print(f\"Accuracy       : {np.mean(accs):.3f} ± {np.std(accs):.3f}\")\n",
    "    print(f\"Sensitivity    : {np.mean(senss):.3f} ± {np.std(senss):.3f}\")\n",
    "    print(f\"Specificity    : {np.mean(specs):.3f} ± {np.std(specs):.3f}\")\n",
    "    print(f\"MCC            : {np.mean(mccs):.3f} ± {np.std(mccs):.3f}\")\n",
    "    print(f\"F1-score       : {np.mean(f1s):.3f} ± {np.std(f1s):.3f}\")\n",
    "    print(f\"AUC-ROC        : {np.mean(aucs):.3f} ± {np.std(aucs):.3f}\")\n",
    "\n",
    "    cm = confusion_matrix(labels, preds, labels=[0,1])\n",
    "    print(\"\\nOverall Confusion Matrix:\")\n",
    "    print(cm)\n",
    "\n",
    "    return {\n",
    "        \"acc\": np.mean(accs),\n",
    "        \"sens\": np.mean(senss),\n",
    "        \"spec\": np.mean(specs),\n",
    "        \"mcc\": np.mean(mccs),\n",
    "        \"f1\": np.mean(f1s),\n",
    "        \"auc\": np.mean(aucs)\n",
    "    }\n",
    "\n",
    "\n",
    "# ===============================\n",
    "# Run for 3 seeds and average\n",
    "# ===============================\n",
    "all_metrics = []\n",
    "seeds = [42, 33, 101]\n",
    "\n",
    "for seed in seeds:\n",
    "    # Reinitialize model + optimizer each run\n",
    "    model = EmsPredictor(embedding_size=len(X_train[0]), hidden_size=128, dropout=0.3, num_classes=2).to(device)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "\n",
    "    metrics = run_pipeline(seed)\n",
    "    all_metrics.append(metrics)\n",
    "\n",
    "# Compute mean ± std across seeds\n",
    "final_metrics = {}\n",
    "for key in all_metrics[0].keys():\n",
    "    vals = [m[key] for m in all_metrics]\n",
    "    final_metrics[key] = (np.mean(vals), np.std(vals))\n",
    "\n",
    "print(\"\\n=== Final Average over 3 seeds ===\")\n",
    "for k, (mean_val, std_val) in final_metrics.items():\n",
    "    print(f\"{k.upper():<12}: {mean_val:.3f} ± {std_val:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98262c79-b330-43f3-8c94-8f2805ca8bc8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
