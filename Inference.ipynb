{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a1a9a4df-72c4-4513-9663-7202c5751cfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load the Saved Model\n",
    "\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class CustomHeadClassifier(nn.Module):\n",
    "    def __init__(self, embedding_size, hidden_size, dropout, num_classes):\n",
    "        super(CustomHeadClassifier, self).__init__()\n",
    "        self.fc1 = nn.Linear(embedding_size, hidden_size)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.fc2 = nn.Linear(hidden_size, num_classes)\n",
    "\n",
    "    def forward(self, x, attention_mask=None):\n",
    "        if attention_mask is not None:\n",
    "            mask = attention_mask.unsqueeze(-1)\n",
    "            x = (x * mask).sum(1) / mask.sum(1)\n",
    "        else:\n",
    "            x = x.mean(dim=1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6fcac9ed-c0bb-46bc-94e5-6fe3a3872202",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of EsmForSequenceClassification were not initialized from the model checkpoint at facebook/esm2_t33_650M_UR50D and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "C:\\Users\\default.DESKTOP-TP42RLP\\anaconda3\\Lib\\site-packages\\peft\\config.py:165: UserWarning: Unexpected keyword arguments ['qalora_group_size', 'target_parameters', 'use_qalora'] for class LoraConfig, these are ignored. This probably means that you're loading a configuration file that was saved using a higher version of the library and additional parameters have been introduced since. It is highly recommended to upgrade the PEFT version before continuing (e.g. by running `pip install -U peft`).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "PeftModelForSequenceClassification(\n",
       "  (base_model): LoraModel(\n",
       "    (model): EsmForSequenceClassification(\n",
       "      (esm): EsmModel(\n",
       "        (embeddings): EsmEmbeddings(\n",
       "          (word_embeddings): Embedding(33, 1280, padding_idx=1)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "          (position_embeddings): Embedding(1026, 1280, padding_idx=1)\n",
       "        )\n",
       "        (encoder): EsmEncoder(\n",
       "          (layer): ModuleList(\n",
       "            (0-32): 33 x EsmLayer(\n",
       "              (attention): EsmAttention(\n",
       "                (self): EsmSelfAttention(\n",
       "                  (query): lora.Linear(\n",
       "                    (base_layer): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "                    (lora_dropout): ModuleDict(\n",
       "                      (default): Dropout(p=0.1, inplace=False)\n",
       "                    )\n",
       "                    (lora_A): ModuleDict(\n",
       "                      (default): Linear(in_features=1280, out_features=16, bias=False)\n",
       "                    )\n",
       "                    (lora_B): ModuleDict(\n",
       "                      (default): Linear(in_features=16, out_features=1280, bias=False)\n",
       "                    )\n",
       "                    (lora_embedding_A): ParameterDict()\n",
       "                    (lora_embedding_B): ParameterDict()\n",
       "                    (lora_magnitude_vector): ModuleDict()\n",
       "                  )\n",
       "                  (key): lora.Linear(\n",
       "                    (base_layer): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "                    (lora_dropout): ModuleDict(\n",
       "                      (default): Dropout(p=0.1, inplace=False)\n",
       "                    )\n",
       "                    (lora_A): ModuleDict(\n",
       "                      (default): Linear(in_features=1280, out_features=16, bias=False)\n",
       "                    )\n",
       "                    (lora_B): ModuleDict(\n",
       "                      (default): Linear(in_features=16, out_features=1280, bias=False)\n",
       "                    )\n",
       "                    (lora_embedding_A): ParameterDict()\n",
       "                    (lora_embedding_B): ParameterDict()\n",
       "                    (lora_magnitude_vector): ModuleDict()\n",
       "                  )\n",
       "                  (value): lora.Linear(\n",
       "                    (base_layer): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "                    (lora_dropout): ModuleDict(\n",
       "                      (default): Dropout(p=0.1, inplace=False)\n",
       "                    )\n",
       "                    (lora_A): ModuleDict(\n",
       "                      (default): Linear(in_features=1280, out_features=16, bias=False)\n",
       "                    )\n",
       "                    (lora_B): ModuleDict(\n",
       "                      (default): Linear(in_features=16, out_features=1280, bias=False)\n",
       "                    )\n",
       "                    (lora_embedding_A): ParameterDict()\n",
       "                    (lora_embedding_B): ParameterDict()\n",
       "                    (lora_magnitude_vector): ModuleDict()\n",
       "                  )\n",
       "                  (dropout): Dropout(p=0.0, inplace=False)\n",
       "                  (rotary_embeddings): RotaryEmbedding()\n",
       "                )\n",
       "                (output): EsmSelfOutput(\n",
       "                  (dense): lora.Linear(\n",
       "                    (base_layer): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "                    (lora_dropout): ModuleDict(\n",
       "                      (default): Dropout(p=0.1, inplace=False)\n",
       "                    )\n",
       "                    (lora_A): ModuleDict(\n",
       "                      (default): Linear(in_features=1280, out_features=16, bias=False)\n",
       "                    )\n",
       "                    (lora_B): ModuleDict(\n",
       "                      (default): Linear(in_features=16, out_features=1280, bias=False)\n",
       "                    )\n",
       "                    (lora_embedding_A): ParameterDict()\n",
       "                    (lora_embedding_B): ParameterDict()\n",
       "                    (lora_magnitude_vector): ModuleDict()\n",
       "                  )\n",
       "                  (dropout): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "                (LayerNorm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "              )\n",
       "              (intermediate): EsmIntermediate(\n",
       "                (dense): lora.Linear(\n",
       "                  (base_layer): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "                  (lora_dropout): ModuleDict(\n",
       "                    (default): Dropout(p=0.1, inplace=False)\n",
       "                  )\n",
       "                  (lora_A): ModuleDict(\n",
       "                    (default): Linear(in_features=1280, out_features=16, bias=False)\n",
       "                  )\n",
       "                  (lora_B): ModuleDict(\n",
       "                    (default): Linear(in_features=16, out_features=5120, bias=False)\n",
       "                  )\n",
       "                  (lora_embedding_A): ParameterDict()\n",
       "                  (lora_embedding_B): ParameterDict()\n",
       "                  (lora_magnitude_vector): ModuleDict()\n",
       "                )\n",
       "              )\n",
       "              (output): EsmOutput(\n",
       "                (dense): lora.Linear(\n",
       "                  (base_layer): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "                  (lora_dropout): ModuleDict(\n",
       "                    (default): Dropout(p=0.1, inplace=False)\n",
       "                  )\n",
       "                  (lora_A): ModuleDict(\n",
       "                    (default): Linear(in_features=5120, out_features=16, bias=False)\n",
       "                  )\n",
       "                  (lora_B): ModuleDict(\n",
       "                    (default): Linear(in_features=16, out_features=1280, bias=False)\n",
       "                  )\n",
       "                  (lora_embedding_A): ParameterDict()\n",
       "                  (lora_embedding_B): ParameterDict()\n",
       "                  (lora_magnitude_vector): ModuleDict()\n",
       "                )\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (LayerNorm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "          )\n",
       "          (emb_layer_norm_after): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (contact_head): EsmContactPredictionHead(\n",
       "          (regression): Linear(in_features=660, out_features=1, bias=True)\n",
       "          (activation): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "      (classifier): ModulesToSaveWrapper(\n",
       "        (original_module): CustomHeadClassifier(\n",
       "          (fc1): Linear(in_features=1280, out_features=128, bias=True)\n",
       "          (dropout): Dropout(p=0.3, inplace=False)\n",
       "          (fc2): Linear(in_features=128, out_features=2, bias=True)\n",
       "        )\n",
       "        (modules_to_save): ModuleDict(\n",
       "          (default): CustomHeadClassifier(\n",
       "            (fc1): Linear(in_features=1280, out_features=128, bias=True)\n",
       "            (dropout): Dropout(p=0.3, inplace=False)\n",
       "            (fc2): Linear(in_features=128, out_features=2, bias=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "from peft import PeftModel\n",
    "\n",
    "# For 650M:\n",
    "base_model_name = \"facebook/esm2_t33_650M_UR50D\"\n",
    "save_dir = \"Saved_Models/LoRA_ESM2_650M_model_with_custom_head\"\n",
    "\n",
    "# 1) tokenizer (optional but recommended)\n",
    "tokenizer = AutoTokenizer.from_pretrained(save_dir)\n",
    "\n",
    "# 2) load the exact base model (must match training)\n",
    "base_model = AutoModelForSequenceClassification.from_pretrained(base_model_name, num_labels=2)\n",
    "\n",
    "# 3) attach your CustomHeadClassifier BEFORE loading the adapter,\n",
    "#    because the adapter keys expect classifier.fc1 / fc2 to exist.\n",
    "embedding_size = base_model.config.hidden_size\n",
    "# Use the same hidden_size you used during training (e.g., 128)\n",
    "base_model.classifier = CustomHeadClassifier(embedding_size, hidden_size=128, dropout=0.3, num_classes=2)\n",
    "\n",
    "# 4) Now load the LoRA adapter into that model\n",
    "#    This will map LoRA tensors into the base_model's modules (including classifier.fc1/fc2)\n",
    "peft_model = PeftModel.from_pretrained(base_model, save_dir)\n",
    "\n",
    "# 5) Load your saved custom head weights (you saved them separately)\n",
    "custom_sd = torch.load(f\"{save_dir}/custom_head.pt\", map_location=\"cpu\")\n",
    "peft_model.model.classifier.load_state_dict(custom_sd)  # PeftModel wraps base in .model\n",
    "\n",
    "# 6) move to device and eval or finetune\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "peft_model.to(device)\n",
    "peft_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d7c27477-a314-4c52-af85-9a717363493f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>sequence</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A6NJG6</td>\n",
       "      <td>MRNRMAPENPQPDPFINRNYSNMKVIPPQDPASPSFTLLSKLECSG...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Q96QS3</td>\n",
       "      <td>MSNQYQEEGCSERPECKSKSPTLLSSYCIDSILGRRSPCKMRLLGA...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Q8N100</td>\n",
       "      <td>MKSCKPSGPPAGARVAPPCAGGTECAGTCAGAGRLESAARRRLAAN...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Q9NY43</td>\n",
       "      <td>MTMEGASGSSFGIDTILSSASSGSPGMMNGDFRPLGEARTADFRSQ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Q96T88</td>\n",
       "      <td>MWIQVRTMDGRQTHTVDSLSRLTKVEELRRKIQELFHVEPGLQRLF...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     name                                           sequence  label\n",
       "0  A6NJG6  MRNRMAPENPQPDPFINRNYSNMKVIPPQDPASPSFTLLSKLECSG...      1\n",
       "1  Q96QS3  MSNQYQEEGCSERPECKSKSPTLLSSYCIDSILGRRSPCKMRLLGA...      1\n",
       "2  Q8N100  MKSCKPSGPPAGARVAPPCAGGTECAGTCAGAGRLESAARRRLAAN...      1\n",
       "3  Q9NY43  MTMEGASGSSFGIDTILSSASSGSPGMMNGDFRPLGEARTADFRSQ...      1\n",
       "4  Q96T88  MWIQVRTMDGRQTHTVDSLSRLTKVEELRRKIQELFHVEPGLQRLF...      1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the data\n",
    "from Bio import SeqIO\n",
    "import pandas as pd\n",
    "\n",
    "local_fasta_path = 'TF_Ind_Labeled_Combined.txt'\n",
    "sequences = []\n",
    "for record in SeqIO.parse(local_fasta_path, \"fasta\"):\n",
    "    # Split the description to extract label\n",
    "    description_parts = record.description.split(\"%\")\n",
    "    label = int(description_parts[-1].split(\"LABEL=\")[1])  # Extracting the numeric part of the label\n",
    "    sequences.append([record.name, str(record.seq), label])\n",
    "\n",
    "# Create dataframe\n",
    "df_test = pd.DataFrame(sequences, columns=[\"name\", \"sequence\", \"label\"])\n",
    "\n",
    "# Display the dataframe\n",
    "df_test.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1aebdf98-e221-409e-943b-883aa9a0ed17",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset\n",
    "\n",
    "df_test[\"label\"] = df_test[\"label\"].astype(int)\n",
    "test_dataset = Dataset.from_pandas(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bb8edcf0-920d-41e6-9d02-3b2ff21af270",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, T5Tokenizer\n",
    "tokenizer =AutoTokenizer.from_pretrained(base_model_name)\n",
    "def tokenize_function(example):\n",
    "    return tokenizer(example[\"sequence\"], truncation=True, padding=\"max_length\", max_length=1024)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bc3fb8fd-f298-460f-8929-2c93e727ec6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e5d46512edad42b9949f506131c582eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/212 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac8dfc7ddf98450e9d5ccaaa16020127",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/212 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "tokenized_dataset = test_dataset.map(tokenize_function, batched=True)\n",
    "tokenized_dataset = tokenized_dataset.train_test_split(test_size=0.2)\n",
    "test_dataset = test_dataset.map(tokenize_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "788a993f-e3aa-404f-bcb3-d147c9f2359c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\default.DESKTOP-TP42RLP\\anaconda3\\Lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\default.DESKTOP-TP42RLP\\AppData\\Local\\Temp\\ipykernel_20880\\3737209683.py:3: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer_test = Trainer(model=peft_model, tokenizer=tokenizer)\n",
      "No label_names provided for model class `PeftModelForSequenceClassification`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import Trainer\n",
    "\n",
    "trainer_test = Trainer(model=peft_model, tokenizer=tokenizer)\n",
    "\n",
    "predictions = trainer_test.predict(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "31aaedf4-7c15-4048-94ab-e1189a4b99c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Metrics on Full Data ===\n",
      "Accuracy: 0.9434\n",
      "Precision: 0.9519\n",
      "Specificity: 0.9528\n",
      "Recall: 0.9340\n",
      "MCC: 0.8870\n",
      "F1: 0.9429\n",
      "AUC: 0.9819\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.95      0.94       106\n",
      "           1       0.95      0.93      0.94       106\n",
      "\n",
      "    accuracy                           0.94       212\n",
      "   macro avg       0.94      0.94      0.94       212\n",
      "weighted avg       0.94      0.94      0.94       212\n",
      "\n",
      "\n",
      "=== Bootstrapped Metrics (Mean ± Std) ===\n",
      "Accuracy: 0.9435 ± 0.0162\n",
      "Precision: 0.9526 ± 0.0213\n",
      "Specificity: 0.9534 ± 0.0213\n",
      "Recall: 0.9338 ± 0.0246\n",
      "MCC: 0.8873 ± 0.0322\n",
      "F1: 0.9429 ± 0.0167\n",
      "AUC: 0.9820 ± 0.0079\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import (\n",
    "    confusion_matrix,\n",
    "    roc_auc_score,\n",
    "    accuracy_score,\n",
    "    classification_report,\n",
    ")\n",
    "from sklearn.utils import resample\n",
    "\n",
    "# --- Extract predictions ---\n",
    "logits = predictions.predictions\n",
    "labels = predictions.label_ids\n",
    "preds = np.argmax(logits, axis=-1)\n",
    "probs = F.softmax(torch.tensor(logits), dim=-1).numpy()  # shape: [N, num_classes]\n",
    "\n",
    "# --- Confusion Matrix ---\n",
    "cm = confusion_matrix(labels, preds)\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "plt.xlabel(\"Predicted Label\")\n",
    "plt.ylabel(\"True Label\")\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.show()\n",
    "\n",
    "# --- Define function to compute metrics ---\n",
    "def compute_metrics(labels, preds, probs):\n",
    "    cm = confusion_matrix(labels, preds)\n",
    "    TN, FP, FN, TP = cm.ravel()\n",
    "\n",
    "    precision = TP / (TP + FP) if (TP + FP) > 0 else 0\n",
    "    specificity = TN / (TN + FP) if (TN + FP) > 0 else 0\n",
    "    recall = TP / (TP + FN) if (TP + FN) > 0 else 0\n",
    "    numerator = (TP * TN) - (FP * FN)\n",
    "    denominator = np.sqrt((TP + FP) * (TP + FN) * (TN + FP) * (TN + FN))\n",
    "    mcc = numerator / denominator if denominator > 0 else 0\n",
    "    f1 = (2 * precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    auc = roc_auc_score(labels, probs[:, 1]) if probs.shape[1] > 1 else np.nan\n",
    "\n",
    "    return {\n",
    "        \"Accuracy\": acc,\n",
    "        \"Precision\": precision,\n",
    "        \"Specificity\": specificity,\n",
    "        \"Recall\": recall,\n",
    "        \"MCC\": mcc,\n",
    "        \"F1\": f1,\n",
    "        \"AUC\": auc,\n",
    "    }\n",
    "\n",
    "# --- Compute metrics on full dataset ---\n",
    "metrics = compute_metrics(labels, preds, probs)\n",
    "print(\"=== Metrics on Full Data ===\")\n",
    "for k, v in metrics.items():\n",
    "    print(f\"{k}: {v:.4f}\")\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(labels, preds))\n",
    "\n",
    "# --- Bootstrapping for Std Dev ---\n",
    "n_bootstraps = 1000\n",
    "rng = np.random.RandomState(42)\n",
    "boot_metrics = {k: [] for k in metrics.keys()}\n",
    "\n",
    "for i in range(n_bootstraps):\n",
    "    indices = rng.randint(0, len(labels), len(labels))  # sample with replacement\n",
    "    boot_labels = labels[indices]\n",
    "    boot_preds = preds[indices]\n",
    "    boot_probs = probs[indices]\n",
    "\n",
    "    m = compute_metrics(boot_labels, boot_preds, boot_probs)\n",
    "    for k in m:\n",
    "        boot_metrics[k].append(m[k])\n",
    "\n",
    "# --- Compute mean and std ---\n",
    "print(\"\\n=== Bootstrapped Metrics (Mean ± Std) ===\")\n",
    "for k in metrics.keys():\n",
    "    mean_val = np.mean(boot_metrics[k])\n",
    "    std_val = np.std(boot_metrics[k])\n",
    "    print(f\"{k}: {mean_val:.4f} ± {std_val:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9be5e848-b4b7-448f-8b3d-cc43fdab3546",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
